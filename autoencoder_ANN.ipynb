{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "torch.Size([100000, 6, 6])\n",
      "torch.Size([100000, 2001])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn   \n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "def load_data(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pkl.load(f)\n",
    "    return data\n",
    "\n",
    "# Load the data\n",
    "Interaction_matrices = load_data('/Users/sanazkazeminia/Documents/Mass_Spec_project/Mass_Spec_ML_Project/binary_interaction_matrices_10binned.pkl')\n",
    "spectral_data = load_data('/Users/sanazkazeminia/Documents/Mass_Spec_project/Mass_Spec_ML_Project/binary_spectra_dataset_10binned.pkl')\n",
    "\n",
    "print(Interaction_matrices.shape)\n",
    "print(spectral_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Set a random seed for reproducibility \n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "autoencoder = torch.load('autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, neurons, latent_size, input): # neurons is a list of the number of neurons in each layer\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        encoder_layers = []\n",
    "        input_size = input\n",
    "        for n in neurons:\n",
    "            encoder_layers.append(nn.Linear(input_size, n))\n",
    "            encoder_layers.append(nn.ReLU())\n",
    "            input_size = n\n",
    "        encoder_layers.append(nn.Linear(input_size, latent_size))\n",
    "        self.encoder = nn.Sequential(*encoder_layers)\n",
    "\n",
    "        # Decoder\n",
    "        decoder_layers = []\n",
    "        input_size = latent_size\n",
    "        for n in reversed(neurons):\n",
    "            decoder_layers.append(nn.Linear(input_size, n))\n",
    "            decoder_layers.append(nn.ReLU())\n",
    "            input_size = n\n",
    "        decoder_layers.append(nn.Linear(input_size, input))\n",
    "        self.decoder = nn.Sequential(*decoder_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurons = 512, 256, 128\n",
    "latent_size = 64\n",
    "input = 2001\n",
    "\n",
    "state_dict = torch.load('autoencoder.pth')\n",
    "model = Autoencoder(neurons, latent_size, input)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100000, 64])\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "encoded_spectra = model.encoder(spectral_data)\n",
    "print(encoded_spectra.shape)\n",
    "print(encoded_spectra.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100000, 2001])\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "decoded_spectra = model.decoder(encoded_spectra)\n",
    "print(decoded_spectra.shape)\n",
    "print(decoded_spectra.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16dabb1d0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for matrix in Interaction_matrices: # forgot to zero out the diagonal\n",
    "    matrix[0,0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100000, 36])\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# flattening and stacking interaction matrices\n",
    "flattened_matrices = [matrix.flatten() for matrix in Interaction_matrices] # storing in an array\n",
    "flattened_matrices = torch.stack(flattened_matrices) # stacking the array\n",
    "print(flattened_matrices.shape)\n",
    "print(flattened_matrices[0]) # example to see the shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80000, 64])\n",
      "torch.Size([10000, 64])\n",
      "torch.Size([10000, 64])\n",
      "torch.Size([80000, 36])\n",
      "torch.Size([10000, 36])\n",
      "torch.Size([10000, 36])\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(encoded_spectra, flattened_matrices, test_size=0.2, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "batch_size = 264 ## 512 is a good number for now. ?? 256 also worked well.\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SpectralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpectralNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(64, 128 ), # 2001 is the number of features in the spectra data\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),  # Added layer\n",
    "            nn.ReLU(),  # Added activation function\n",
    "            nn.Linear(128, 36), # 36 is the number of features in the flattened interaction matrix (multilabel classification)\n",
    "            nn.Sigmoid() # sigmoid activation function for multilabel classification \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "\n",
    "model = SpectralNet().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001) # lr = 0.001 works well\n",
    "scheduler = CyclicLR(optimizer, base_lr=1e-7, max_lr=1e-4, step_size_up=2000, mode='triangular')\n",
    "\n",
    "#criterion = AsymmetricLossMultiLabel(gamma_neg=4, gamma_pos=0, clip=1.0) \n",
    "criterion = nn.BCELoss() # binary cross entropy loss for multilabel classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the gradient norms\n",
    "def compute_gradient_norms(model):\n",
    "    total_norm = 0.0\n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None:\n",
    "            param_norm = p.grad.data.norm(2)\n",
    "            total_norm += param_norm.item() ** 2\n",
    "    total_norm = total_norm ** (1. / 2)\n",
    "    return total_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import wandb\n",
    "from sklearn.metrics import f1_score, hamming_loss, precision_score, recall_score, jaccard_score\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, scheduler, criterion, num_epochs, threshold):\n",
    "    train_epoch_losses = []\n",
    "    val_epoch_losses = []\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Set model to training mode\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            X, y = batch\n",
    "            X = X.detach().to(device)\n",
    "            y = y.detach().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            # Forward pass\n",
    "            y_pred = model(X)\n",
    "            loss = criterion(y_pred, y)\n",
    "            \n",
    "            # Accumulate batch loss\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # Backprop and optimize\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            gradient_norm = compute_gradient_norms(model)\n",
    "            optimizer.step()\n",
    "        \n",
    "            scheduler.step()\n",
    "\n",
    "        # Average loss for the epoch\n",
    "        train_loss /= len(train_loader)\n",
    "        train_epoch_losses.append(train_loss)\n",
    "                \n",
    "\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}\")        \n",
    "\n",
    "\n",
    "        # Set model to evaluation mode\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        y_true_list = []\n",
    "        y_pred_list = []  \n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                X, y = batch\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(X)\n",
    "                loss = criterion(outputs, y)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                binary_predictions = (outputs > threshold).float()\n",
    "                \n",
    "                y_pred_list.append(binary_predictions.cpu().numpy())\n",
    "                y_true_list.append(y.cpu().numpy())\n",
    "            \n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "            val_epoch_losses.append(val_loss)\n",
    "\n",
    "\n",
    "        y_true = np.concatenate(y_true_list, axis=0)\n",
    "        y_pred = np.concatenate(y_pred_list, axis=0)\n",
    "\n",
    "        y_true = y_true.astype(int)\n",
    "        y_pred = y_pred.astype(int)\n",
    "\n",
    "        hamming_loss_value = hamming_loss(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, average='micro', zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, average='micro', zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, average='micro', zero_division=0)\n",
    "        jaccard_score_value = jaccard_score(y_true, y_pred, average='micro')\n",
    "\n",
    "                    \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Val Loss: {val_loss:.4f},jacquard_loss:{jaccard_score_value}, hammingloss: {hamming_loss_value:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "        wandb.log({\n",
    "            \"Train Loss\": train_loss,\n",
    "            \"Val Loss\": val_loss,\n",
    "            \"Hamming Loss\": hamming_loss_value,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1\": f1,\n",
    "            \"Jaccard Score\": jaccard_score_value,\n",
    "            \"gradient_norm\": gradient_norm\n",
    "        })\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "                state = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'loss': train_loss,\n",
    "                }\n",
    "                torch.save(state, \"binary_model.pth\") ## save the model every x epochs\n",
    "                print(\"Saved model to:\", \"binary_model.pth\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    wandb.finish()\n",
    "    return train_epoch_losses, val_epoch_losses, y_true , y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sanazkazeminia/Documents/Mass_Spec_project/Mass_Spec_ML_Project/wandb/run-20240523_172037-971d1656</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sanaz_team/AutoEncoder_SpectralNet_Binary_10binned/runs/971d1656' target=\"_blank\">crisp-surf-8</a></strong> to <a href='https://wandb.ai/sanaz_team/AutoEncoder_SpectralNet_Binary_10binned' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sanaz_team/AutoEncoder_SpectralNet_Binary_10binned' target=\"_blank\">https://wandb.ai/sanaz_team/AutoEncoder_SpectralNet_Binary_10binned</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sanaz_team/AutoEncoder_SpectralNet_Binary_10binned/runs/971d1656' target=\"_blank\">https://wandb.ai/sanaz_team/AutoEncoder_SpectralNet_Binary_10binned/runs/971d1656</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.6923\n",
      "Epoch [1/100], Val Loss: 0.6911,jacquard_loss:0.29960397543129114, hammingloss: 0.4868, Precision: 0.4998, Recall: 0.4279, F1: 0.4611\n",
      "Epoch [2/100], Train Loss: 0.6832\n",
      "Epoch [2/100], Val Loss: 0.6744,jacquard_loss:0.3528765074735151, hammingloss: 0.4856, Precision: 0.5010, Recall: 0.5441, F1: 0.5217\n",
      "Epoch [3/100], Train Loss: 0.6741\n",
      "Epoch [3/100], Val Loss: 0.6740,jacquard_loss:0.35177981189551727, hammingloss: 0.4865, Precision: 0.5002, Recall: 0.5424, F1: 0.5205\n",
      "Epoch [4/100], Train Loss: 0.6740\n",
      "Epoch [4/100], Val Loss: 0.6740,jacquard_loss:0.35164042116171057, hammingloss: 0.4866, Precision: 0.5000, Recall: 0.5423, F1: 0.5203\n",
      "Epoch [5/100], Train Loss: 0.6740\n",
      "Epoch [5/100], Val Loss: 0.6741,jacquard_loss:0.32718073715816953, hammingloss: 0.4861, Precision: 0.5006, Recall: 0.4857, F1: 0.4930\n",
      "Epoch [6/100], Train Loss: 0.6740\n",
      "Epoch [6/100], Val Loss: 0.6741,jacquard_loss:0.3130143356657078, hammingloss: 0.4863, Precision: 0.5005, Recall: 0.4552, F1: 0.4768\n",
      "Epoch [7/100], Train Loss: 0.6740\n",
      "Epoch [7/100], Val Loss: 0.6740,jacquard_loss:0.31385982997103473, hammingloss: 0.4863, Precision: 0.5005, Recall: 0.4570, F1: 0.4778\n",
      "Epoch [8/100], Train Loss: 0.6740\n",
      "Epoch [8/100], Val Loss: 0.6740,jacquard_loss:0.3254127294868435, hammingloss: 0.4863, Precision: 0.5005, Recall: 0.4820, F1: 0.4910\n",
      "Epoch [9/100], Train Loss: 0.6740\n",
      "Epoch [9/100], Val Loss: 0.6740,jacquard_loss:0.32815841918724536, hammingloss: 0.4860, Precision: 0.5007, Recall: 0.4878, F1: 0.4942\n",
      "Epoch [10/100], Train Loss: 0.6740\n",
      "Epoch [10/100], Val Loss: 0.6740,jacquard_loss:0.3200197449481306, hammingloss: 0.4860, Precision: 0.5008, Recall: 0.4699, F1: 0.4849\n",
      "Saved model to: binary_model.pth\n",
      "Epoch [11/100], Train Loss: 0.6740\n",
      "Epoch [11/100], Val Loss: 0.6739,jacquard_loss:0.3259886962146179, hammingloss: 0.4863, Precision: 0.5004, Recall: 0.4833, F1: 0.4917\n",
      "Epoch [12/100], Train Loss: 0.6739\n",
      "Epoch [12/100], Val Loss: 0.6739,jacquard_loss:0.3577553954723514, hammingloss: 0.4864, Precision: 0.5003, Recall: 0.5567, F1: 0.5270\n",
      "Epoch [13/100], Train Loss: 0.6739\n",
      "Epoch [13/100], Val Loss: 0.6739,jacquard_loss:0.3472441091552575, hammingloss: 0.4867, Precision: 0.5000, Recall: 0.5320, F1: 0.5155\n",
      "Epoch [14/100], Train Loss: 0.6739\n",
      "Epoch [14/100], Val Loss: 0.6739,jacquard_loss:0.3477182096836592, hammingloss: 0.4871, Precision: 0.4996, Recall: 0.5335, F1: 0.5160\n",
      "Epoch [15/100], Train Loss: 0.6739\n",
      "Epoch [15/100], Val Loss: 0.6739,jacquard_loss:0.3264048143074816, hammingloss: 0.4863, Precision: 0.5004, Recall: 0.4842, F1: 0.4922\n",
      "Epoch [16/100], Train Loss: 0.6739\n",
      "Epoch [16/100], Val Loss: 0.6740,jacquard_loss:0.3241101685102704, hammingloss: 0.4864, Precision: 0.5003, Recall: 0.4793, F1: 0.4896\n",
      "Epoch [17/100], Train Loss: 0.6740\n",
      "Epoch [17/100], Val Loss: 0.6740,jacquard_loss:0.32284789994659896, hammingloss: 0.4861, Precision: 0.5007, Recall: 0.4762, F1: 0.4881\n",
      "Epoch [18/100], Train Loss: 0.6740\n",
      "Epoch [18/100], Val Loss: 0.6740,jacquard_loss:0.32758110564194787, hammingloss: 0.4861, Precision: 0.5006, Recall: 0.4866, F1: 0.4935\n",
      "Epoch [19/100], Train Loss: 0.6740\n",
      "Epoch [19/100], Val Loss: 0.6740,jacquard_loss:0.3258063025242449, hammingloss: 0.4862, Precision: 0.5005, Recall: 0.4828, F1: 0.4915\n",
      "Epoch [20/100], Train Loss: 0.6740\n",
      "Epoch [20/100], Val Loss: 0.6740,jacquard_loss:0.32036951536996155, hammingloss: 0.4866, Precision: 0.5001, Recall: 0.4713, F1: 0.4853\n",
      "Saved model to: binary_model.pth\n",
      "Epoch [21/100], Train Loss: 0.6740\n",
      "Epoch [21/100], Val Loss: 0.6740,jacquard_loss:0.3120526655235878, hammingloss: 0.4859, Precision: 0.5009, Recall: 0.4529, F1: 0.4757\n",
      "Epoch [22/100], Train Loss: 0.6740\n",
      "Epoch [22/100], Val Loss: 0.6740,jacquard_loss:0.3201466225556436, hammingloss: 0.4863, Precision: 0.5004, Recall: 0.4706, F1: 0.4850\n",
      "Epoch [23/100], Train Loss: 0.6739\n",
      "Epoch [23/100], Val Loss: 0.6739,jacquard_loss:0.3303666022833757, hammingloss: 0.4863, Precision: 0.5004, Recall: 0.4930, F1: 0.4967\n",
      "Epoch [24/100], Train Loss: 0.6739\n",
      "Epoch [24/100], Val Loss: 0.6739,jacquard_loss:0.35663575029764966, hammingloss: 0.4863, Precision: 0.5003, Recall: 0.5539, F1: 0.5258\n",
      "Epoch [25/100], Train Loss: 0.6739\n",
      "Epoch [25/100], Val Loss: 0.6739,jacquard_loss:0.34358661750076663, hammingloss: 0.4876, Precision: 0.4992, Recall: 0.5244, F1: 0.5114\n",
      "Epoch [26/100], Train Loss: 0.6739\n",
      "Epoch [26/100], Val Loss: 0.6739,jacquard_loss:0.35040715252916843, hammingloss: 0.4864, Precision: 0.5003, Recall: 0.5391, F1: 0.5190\n",
      "Epoch [27/100], Train Loss: 0.6739\n",
      "Epoch [27/100], Val Loss: 0.6739,jacquard_loss:0.33868200245121144, hammingloss: 0.4871, Precision: 0.4996, Recall: 0.5126, F1: 0.5060\n",
      "Epoch [28/100], Train Loss: 0.6739\n",
      "Epoch [28/100], Val Loss: 0.6739,jacquard_loss:0.3613203351148767, hammingloss: 0.4866, Precision: 0.5001, Recall: 0.5657, F1: 0.5308\n",
      "Epoch [29/100], Train Loss: 0.6739\n",
      "Epoch [29/100], Val Loss: 0.6739,jacquard_loss:0.3445025315934631, hammingloss: 0.4866, Precision: 0.5001, Recall: 0.5254, F1: 0.5125\n",
      "Epoch [30/100], Train Loss: 0.6739\n",
      "Epoch [30/100], Val Loss: 0.6739,jacquard_loss:0.3324138351456592, hammingloss: 0.4867, Precision: 0.5000, Recall: 0.4980, F1: 0.4990\n",
      "Saved model to: binary_model.pth\n",
      "Epoch [31/100], Train Loss: 0.6739\n",
      "Epoch [31/100], Val Loss: 0.6740,jacquard_loss:0.3275325263646869, hammingloss: 0.4866, Precision: 0.5001, Recall: 0.4869, F1: 0.4934\n",
      "Epoch [32/100], Train Loss: 0.6739\n",
      "Epoch [32/100], Val Loss: 0.6740,jacquard_loss:0.32546528860403795, hammingloss: 0.4868, Precision: 0.4999, Recall: 0.4826, F1: 0.4911\n",
      "Epoch [33/100], Train Loss: 0.6739\n",
      "Epoch [33/100], Val Loss: 0.6740,jacquard_loss:0.3279583496269715, hammingloss: 0.4869, Precision: 0.4998, Recall: 0.4882, F1: 0.4939\n",
      "Epoch [34/100], Train Loss: 0.6739\n",
      "Epoch [34/100], Val Loss: 0.6739,jacquard_loss:0.3398889106612604, hammingloss: 0.4866, Precision: 0.5001, Recall: 0.5148, F1: 0.5073\n",
      "Epoch [35/100], Train Loss: 0.6739\n",
      "Epoch [35/100], Val Loss: 0.6739,jacquard_loss:0.3536953409778486, hammingloss: 0.4866, Precision: 0.5001, Recall: 0.5472, F1: 0.5226\n",
      "Epoch [36/100], Train Loss: 0.6739\n",
      "Epoch [36/100], Val Loss: 0.6739,jacquard_loss:0.3589973273274371, hammingloss: 0.4870, Precision: 0.4997, Recall: 0.5604, F1: 0.5283\n",
      "Epoch [37/100], Train Loss: 0.6739\n",
      "Epoch [37/100], Val Loss: 0.6739,jacquard_loss:0.34617591605869336, hammingloss: 0.4874, Precision: 0.4993, Recall: 0.5303, F1: 0.5143\n",
      "Epoch [38/100], Train Loss: 0.6739\n",
      "Epoch [38/100], Val Loss: 0.6739,jacquard_loss:0.34996762197265446, hammingloss: 0.4880, Precision: 0.4988, Recall: 0.5398, F1: 0.5185\n",
      "Epoch [39/100], Train Loss: 0.6739\n",
      "Epoch [39/100], Val Loss: 0.6739,jacquard_loss:0.35295508798380004, hammingloss: 0.4864, Precision: 0.5003, Recall: 0.5452, F1: 0.5218\n",
      "Epoch [40/100], Train Loss: 0.6739\n",
      "Epoch [40/100], Val Loss: 0.6739,jacquard_loss:0.35110571207413144, hammingloss: 0.4867, Precision: 0.5000, Recall: 0.5411, F1: 0.5197\n",
      "Saved model to: binary_model.pth\n",
      "Epoch [41/100], Train Loss: 0.6739\n",
      "Epoch [41/100], Val Loss: 0.6739,jacquard_loss:0.35013950665709487, hammingloss: 0.4878, Precision: 0.4989, Recall: 0.5400, F1: 0.5187\n",
      "Epoch [42/100], Train Loss: 0.6739\n",
      "Epoch [42/100], Val Loss: 0.6739,jacquard_loss:0.3430592991913747, hammingloss: 0.4874, Precision: 0.4993, Recall: 0.5230, F1: 0.5109\n",
      "Epoch [43/100], Train Loss: 0.6739\n",
      "Epoch [43/100], Val Loss: 0.6739,jacquard_loss:0.3584572079079625, hammingloss: 0.4868, Precision: 0.4999, Recall: 0.5589, F1: 0.5277\n",
      "Epoch [44/100], Train Loss: 0.6739\n",
      "Epoch [44/100], Val Loss: 0.6739,jacquard_loss:0.35629076805547394, hammingloss: 0.4868, Precision: 0.4999, Recall: 0.5537, F1: 0.5254\n",
      "Epoch [45/100], Train Loss: 0.6739\n",
      "Epoch [45/100], Val Loss: 0.6739,jacquard_loss:0.35065483734685254, hammingloss: 0.4867, Precision: 0.5000, Recall: 0.5400, F1: 0.5192\n",
      "Epoch [46/100], Train Loss: 0.6739\n",
      "Epoch [46/100], Val Loss: 0.6739,jacquard_loss:0.34492712438584816, hammingloss: 0.4867, Precision: 0.5000, Recall: 0.5265, F1: 0.5129\n",
      "Epoch [47/100], Train Loss: 0.6739\n",
      "Epoch [47/100], Val Loss: 0.6739,jacquard_loss:0.3572882325545577, hammingloss: 0.4868, Precision: 0.4999, Recall: 0.5561, F1: 0.5265\n",
      "Epoch [48/100], Train Loss: 0.6739\n",
      "Epoch [48/100], Val Loss: 0.6739,jacquard_loss:0.3491252751494994, hammingloss: 0.4871, Precision: 0.4996, Recall: 0.5368, F1: 0.5176\n",
      "Epoch [49/100], Train Loss: 0.6739\n",
      "Epoch [49/100], Val Loss: 0.6739,jacquard_loss:0.3547406128392135, hammingloss: 0.4869, Precision: 0.4999, Recall: 0.5499, F1: 0.5237\n",
      "Epoch [50/100], Train Loss: 0.6739\n",
      "Epoch [50/100], Val Loss: 0.6739,jacquard_loss:0.3487780361785859, hammingloss: 0.4877, Precision: 0.4990, Recall: 0.5367, F1: 0.5172\n",
      "Saved model to: binary_model.pth\n",
      "Epoch [51/100], Train Loss: 0.6739\n",
      "Epoch [51/100], Val Loss: 0.6739,jacquard_loss:0.34390399161237173, hammingloss: 0.4867, Precision: 0.5000, Recall: 0.5242, F1: 0.5118\n",
      "Epoch [52/100], Train Loss: 0.6739\n",
      "Epoch [52/100], Val Loss: 0.6739,jacquard_loss:0.3329215565163681, hammingloss: 0.4860, Precision: 0.5007, Recall: 0.4984, F1: 0.4995\n",
      "Epoch [53/100], Train Loss: 0.6739\n",
      "Epoch [53/100], Val Loss: 0.6739,jacquard_loss:0.34116753406937217, hammingloss: 0.4867, Precision: 0.5000, Recall: 0.5178, F1: 0.5088\n",
      "Epoch [54/100], Train Loss: 0.6739\n",
      "Epoch [54/100], Val Loss: 0.6739,jacquard_loss:0.3486526256335558, hammingloss: 0.4869, Precision: 0.4998, Recall: 0.5355, F1: 0.5170\n",
      "Epoch [55/100], Train Loss: 0.6739\n",
      "Epoch [55/100], Val Loss: 0.6739,jacquard_loss:0.3503250984922539, hammingloss: 0.4874, Precision: 0.4993, Recall: 0.5400, F1: 0.5189\n",
      "Epoch [56/100], Train Loss: 0.6739\n",
      "Epoch [56/100], Val Loss: 0.6739,jacquard_loss:0.3605346388014402, hammingloss: 0.4869, Precision: 0.4998, Recall: 0.5641, F1: 0.5300\n",
      "Epoch [57/100], Train Loss: 0.6739\n",
      "Epoch [57/100], Val Loss: 0.6739,jacquard_loss:0.352541133185079, hammingloss: 0.4869, Precision: 0.4998, Recall: 0.5447, F1: 0.5213\n",
      "Epoch [58/100], Train Loss: 0.6739\n",
      "Epoch [58/100], Val Loss: 0.6739,jacquard_loss:0.3607957759070524, hammingloss: 0.4866, Precision: 0.5001, Recall: 0.5643, F1: 0.5303\n",
      "Epoch [59/100], Train Loss: 0.6739\n",
      "Epoch [59/100], Val Loss: 0.6739,jacquard_loss:0.3568686460894777, hammingloss: 0.4868, Precision: 0.4999, Recall: 0.5550, F1: 0.5260\n",
      "Epoch [60/100], Train Loss: 0.6739\n",
      "Epoch [60/100], Val Loss: 0.6739,jacquard_loss:0.35690834171887736, hammingloss: 0.4864, Precision: 0.5003, Recall: 0.5547, F1: 0.5261\n",
      "Saved model to: binary_model.pth\n",
      "Epoch [61/100], Train Loss: 0.6739\n",
      "Epoch [61/100], Val Loss: 0.6739,jacquard_loss:0.3553537791382152, hammingloss: 0.4867, Precision: 0.5000, Recall: 0.5513, F1: 0.5244\n",
      "Epoch [62/100], Train Loss: 0.6739\n",
      "Epoch [62/100], Val Loss: 0.6739,jacquard_loss:0.3498619014959127, hammingloss: 0.4871, Precision: 0.4996, Recall: 0.5386, F1: 0.5184\n",
      "Epoch [63/100], Train Loss: 0.6739\n",
      "Epoch [63/100], Val Loss: 0.6739,jacquard_loss:0.3475930853538267, hammingloss: 0.4870, Precision: 0.4997, Recall: 0.5331, F1: 0.5159\n",
      "Epoch [64/100], Train Loss: 0.6739\n",
      "Epoch [64/100], Val Loss: 0.6739,jacquard_loss:0.3426706258188275, hammingloss: 0.4864, Precision: 0.5003, Recall: 0.5210, F1: 0.5104\n",
      "Epoch [65/100], Train Loss: 0.6739\n",
      "Epoch [65/100], Val Loss: 0.6739,jacquard_loss:0.33332571036533076, hammingloss: 0.4859, Precision: 0.5009, Recall: 0.4991, F1: 0.5000\n",
      "Epoch [66/100], Train Loss: 0.6739\n",
      "Epoch [66/100], Val Loss: 0.6739,jacquard_loss:0.35334433772401136, hammingloss: 0.4864, Precision: 0.5002, Recall: 0.5461, F1: 0.5222\n",
      "Epoch [67/100], Train Loss: 0.6739\n",
      "Epoch [67/100], Val Loss: 0.6739,jacquard_loss:0.3475479903180209, hammingloss: 0.4859, Precision: 0.5007, Recall: 0.5319, F1: 0.5158\n",
      "Epoch [68/100], Train Loss: 0.6739\n",
      "Epoch [68/100], Val Loss: 0.6739,jacquard_loss:0.3467696540206447, hammingloss: 0.4868, Precision: 0.4999, Recall: 0.5309, F1: 0.5150\n",
      "Epoch [69/100], Train Loss: 0.6739\n",
      "Epoch [69/100], Val Loss: 0.6739,jacquard_loss:0.3503253394201696, hammingloss: 0.4870, Precision: 0.4997, Recall: 0.5396, F1: 0.5189\n",
      "Epoch [70/100], Train Loss: 0.6739\n",
      "Epoch [70/100], Val Loss: 0.6739,jacquard_loss:0.3558037700331266, hammingloss: 0.4867, Precision: 0.5000, Recall: 0.5523, F1: 0.5249\n",
      "Saved model to: binary_model.pth\n",
      "Epoch [71/100], Train Loss: 0.6739\n",
      "Epoch [71/100], Val Loss: 0.6739,jacquard_loss:0.3550330503949476, hammingloss: 0.4865, Precision: 0.5002, Recall: 0.5503, F1: 0.5240\n",
      "Epoch [72/100], Train Loss: 0.6739\n",
      "Epoch [72/100], Val Loss: 0.6739,jacquard_loss:0.34438684806407543, hammingloss: 0.4866, Precision: 0.5001, Recall: 0.5252, F1: 0.5123\n",
      "Epoch [73/100], Train Loss: 0.6739\n",
      "Epoch [73/100], Val Loss: 0.6739,jacquard_loss:0.35041409979193017, hammingloss: 0.4865, Precision: 0.5002, Recall: 0.5392, F1: 0.5190\n",
      "Epoch [74/100], Train Loss: 0.6739\n",
      "Epoch [74/100], Val Loss: 0.6739,jacquard_loss:0.3534518396031418, hammingloss: 0.4866, Precision: 0.5001, Recall: 0.5465, F1: 0.5223\n",
      "Epoch [75/100], Train Loss: 0.6739\n",
      "Epoch [75/100], Val Loss: 0.6739,jacquard_loss:0.35308755930513763, hammingloss: 0.4867, Precision: 0.5000, Recall: 0.5458, F1: 0.5219\n",
      "Epoch [76/100], Train Loss: 0.6739\n",
      "Epoch [76/100], Val Loss: 0.6739,jacquard_loss:0.3506074827029734, hammingloss: 0.4862, Precision: 0.5004, Recall: 0.5394, F1: 0.5192\n",
      "Epoch [77/100], Train Loss: 0.6739\n",
      "Epoch [77/100], Val Loss: 0.6739,jacquard_loss:0.34409150189629584, hammingloss: 0.4862, Precision: 0.5005, Recall: 0.5240, F1: 0.5120\n",
      "Epoch [78/100], Train Loss: 0.6739\n",
      "Epoch [78/100], Val Loss: 0.6739,jacquard_loss:0.33518345452196974, hammingloss: 0.4861, Precision: 0.5006, Recall: 0.5036, F1: 0.5021\n",
      "Epoch [79/100], Train Loss: 0.6739\n",
      "Epoch [79/100], Val Loss: 0.6739,jacquard_loss:0.3483092075364867, hammingloss: 0.4860, Precision: 0.5007, Recall: 0.5337, F1: 0.5167\n",
      "Epoch [80/100], Train Loss: 0.6739\n",
      "Epoch [80/100], Val Loss: 0.6739,jacquard_loss:0.33519629484690405, hammingloss: 0.4860, Precision: 0.5007, Recall: 0.5035, F1: 0.5021\n",
      "Saved model to: binary_model.pth\n",
      "Epoch [81/100], Train Loss: 0.6739\n",
      "Epoch [81/100], Val Loss: 0.6739,jacquard_loss:0.34920882723552304, hammingloss: 0.4863, Precision: 0.5003, Recall: 0.5362, F1: 0.5176\n",
      "Epoch [82/100], Train Loss: 0.6739\n",
      "Epoch [82/100], Val Loss: 0.6739,jacquard_loss:0.35067151443199523, hammingloss: 0.4862, Precision: 0.5005, Recall: 0.5395, F1: 0.5193\n",
      "Epoch [83/100], Train Loss: 0.6739\n",
      "Epoch [83/100], Val Loss: 0.6739,jacquard_loss:0.3496440321951038, hammingloss: 0.4859, Precision: 0.5007, Recall: 0.5368, F1: 0.5181\n",
      "Epoch [84/100], Train Loss: 0.6739\n",
      "Epoch [84/100], Val Loss: 0.6739,jacquard_loss:0.3468142742007701, hammingloss: 0.4863, Precision: 0.5004, Recall: 0.5305, F1: 0.5150\n",
      "Epoch [85/100], Train Loss: 0.6739\n",
      "Epoch [85/100], Val Loss: 0.6739,jacquard_loss:0.3512979233967429, hammingloss: 0.4858, Precision: 0.5008, Recall: 0.5406, F1: 0.5199\n",
      "Epoch [86/100], Train Loss: 0.6739\n",
      "Epoch [86/100], Val Loss: 0.6739,jacquard_loss:0.3533135158318174, hammingloss: 0.4859, Precision: 0.5008, Recall: 0.5454, F1: 0.5221\n",
      "Epoch [87/100], Train Loss: 0.6739\n",
      "Epoch [87/100], Val Loss: 0.6739,jacquard_loss:0.35290809530856887, hammingloss: 0.4858, Precision: 0.5008, Recall: 0.5444, F1: 0.5217\n",
      "Epoch [88/100], Train Loss: 0.6739\n",
      "Epoch [88/100], Val Loss: 0.6739,jacquard_loss:0.35308755181045415, hammingloss: 0.4860, Precision: 0.5006, Recall: 0.5450, F1: 0.5219\n",
      "Epoch [89/100], Train Loss: 0.6739\n",
      "Epoch [89/100], Val Loss: 0.6739,jacquard_loss:0.3545096272110452, hammingloss: 0.4854, Precision: 0.5012, Recall: 0.5478, F1: 0.5235\n",
      "Epoch [90/100], Train Loss: 0.6739\n",
      "Epoch [90/100], Val Loss: 0.6739,jacquard_loss:0.35910610102905394, hammingloss: 0.4858, Precision: 0.5008, Recall: 0.5593, F1: 0.5284\n",
      "Saved model to: binary_model.pth\n",
      "Epoch [91/100], Train Loss: 0.6739\n",
      "Epoch [91/100], Val Loss: 0.6739,jacquard_loss:0.34787896423468495, hammingloss: 0.4856, Precision: 0.5011, Recall: 0.5322, F1: 0.5162\n",
      "Epoch [92/100], Train Loss: 0.6739\n",
      "Epoch [92/100], Val Loss: 0.6739,jacquard_loss:0.3498615009945902, hammingloss: 0.4857, Precision: 0.5009, Recall: 0.5371, F1: 0.5184\n",
      "Epoch [93/100], Train Loss: 0.6739\n",
      "Epoch [93/100], Val Loss: 0.6739,jacquard_loss:0.34834322655604133, hammingloss: 0.4861, Precision: 0.5006, Recall: 0.5339, F1: 0.5167\n",
      "Epoch [94/100], Train Loss: 0.6739\n",
      "Epoch [94/100], Val Loss: 0.6739,jacquard_loss:0.3598148453080118, hammingloss: 0.4860, Precision: 0.5007, Recall: 0.5612, F1: 0.5292\n",
      "Epoch [95/100], Train Loss: 0.6739\n",
      "Epoch [95/100], Val Loss: 0.6739,jacquard_loss:0.36487507537615427, hammingloss: 0.4857, Precision: 0.5009, Recall: 0.5733, F1: 0.5347\n",
      "Epoch [96/100], Train Loss: 0.6739\n",
      "Epoch [96/100], Val Loss: 0.6739,jacquard_loss:0.3601751811998522, hammingloss: 0.4858, Precision: 0.5008, Recall: 0.5619, F1: 0.5296\n",
      "Epoch [97/100], Train Loss: 0.6739\n",
      "Epoch [97/100], Val Loss: 0.6739,jacquard_loss:0.35347055582875164, hammingloss: 0.4857, Precision: 0.5009, Recall: 0.5456, F1: 0.5223\n",
      "Epoch [98/100], Train Loss: 0.6739\n",
      "Epoch [98/100], Val Loss: 0.6739,jacquard_loss:0.35476247622916013, hammingloss: 0.4854, Precision: 0.5012, Recall: 0.5483, F1: 0.5237\n",
      "Epoch [99/100], Train Loss: 0.6739\n",
      "Epoch [99/100], Val Loss: 0.6739,jacquard_loss:0.3501295634935367, hammingloss: 0.4863, Precision: 0.5004, Recall: 0.5383, F1: 0.5187\n",
      "Epoch [100/100], Train Loss: 0.6739\n",
      "Epoch [100/100], Val Loss: 0.6739,jacquard_loss:0.3555689862945042, hammingloss: 0.4857, Precision: 0.5009, Recall: 0.5507, F1: 0.5246\n",
      "Saved model to: binary_model.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>F1</td><td>▁▇▃▄▄▆▄▄▂▅▇█▄▆█▇▇▇▆▇▆▇██▇▆▆▇▆▇▆▇▇▆▇▇▇█▇▇</td></tr><tr><td>Hamming Loss</td><td>▅▄▃▃▃▅▄▃▂▄▄▄▄▄▆▄█▅▅▅▅▅▅▅▅▄▂▆▄▄▃▃▃▃▂▁▂▃▂▂</td></tr><tr><td>Jaccard Score</td><td>▁▇▃▄▄▆▄▄▂▄▇█▄▆█▇▇▇▆▇▆▇█▇▇▆▆▇▆▇▆▇▇▆▇▇▇█▇▇</td></tr><tr><td>Precision</td><td>▄▅▆▆▆▄▅▆▇▆▅▅▅▅▃▅▁▄▄▄▄▄▄▄▄▅▇▃▅▅▆▇▆▆▇█▇▆▇▇</td></tr><tr><td>Recall</td><td>▁▇▂▄▄▆▄▄▂▄▇█▄▅█▇▇▇▆▇▆▆█▇▇▆▆▇▆▇▆▆▇▆▇▇▇█▇▇</td></tr><tr><td>Train Loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val Loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>gradient_norm</td><td>▁██▇███▇▅▅▅▅▄▄▃▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>F1</td><td>0.5246</td></tr><tr><td>Hamming Loss</td><td>0.48574</td></tr><tr><td>Jaccard Score</td><td>0.35557</td></tr><tr><td>Precision</td><td>0.50089</td></tr><tr><td>Recall</td><td>0.55068</td></tr><tr><td>Train Loss</td><td>0.67389</td></tr><tr><td>Val Loss</td><td>0.67392</td></tr><tr><td>gradient_norm</td><td>0.05158</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">crisp-surf-8</strong> at: <a href='https://wandb.ai/sanaz_team/AutoEncoder_SpectralNet_Binary_10binned/runs/971d1656' target=\"_blank\">https://wandb.ai/sanaz_team/AutoEncoder_SpectralNet_Binary_10binned/runs/971d1656</a><br/> View project at: <a href='https://wandb.ai/sanaz_team/AutoEncoder_SpectralNet_Binary_10binned' target=\"_blank\">https://wandb.ai/sanaz_team/AutoEncoder_SpectralNet_Binary_10binned</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240523_172037-971d1656/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"AutoEncoder_SpectralNet_Binary_10binned\",\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"architecture\": \"ANN\",\n",
    "    \"dataset\": \"binary_10binned\",\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 256,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"loss_function\": \"BCELoss\",\n",
    "    \"scheduler\": \"CyclicLR\",\n",
    "    \"max_lr\": 1e-2,\n",
    "    \"base_lr\": 1e-4,\n",
    "    })\n",
    "\n",
    "train_epoch_losses, val_epoch_losses, y_true_list, y_pred_list = train(model, train_loader, val_loader, optimizer, scheduler, criterion, num_epochs=100, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 36)\n",
      "(10000, 36)\n",
      "[0 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 0 1 0]\n",
      "[0 0 0 1 1 1 0 1 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_true_list.shape)\n",
    "print(y_pred_list.shape)\n",
    "\n",
    "print(y_true_list[0])\n",
    "print(y_pred_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0022\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model,loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            X, y = batch\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, y)\n",
    "            val_loss += loss.item()\n",
    "            y_pred.extend(outputs.cpu().numpy())\n",
    "            y_true.extend(y.cpu().numpy())\n",
    "            val_loss /= len(loader)\n",
    "    \n",
    "    print(f\"Loss: {val_loss:.4f}\")\n",
    "\n",
    "    return y_true, y_pred\n",
    "\n",
    "y_true, y_pred = evaluate(model, train_loader, criterion)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0.]\n",
      "[2.3122513e-05 4.9266773e-01 4.9645618e-01 5.0330520e-01 5.0295907e-01\n",
      " 5.0152701e-01 4.9854192e-01 5.0247651e-01 4.9489063e-01 5.0807989e-01\n",
      " 5.0239098e-01 5.1022941e-01 4.9325010e-01 5.0291073e-01 4.9098292e-01\n",
      " 4.9441391e-01 4.9656031e-01 4.9320272e-01 4.9932137e-01 5.0187761e-01\n",
      " 5.0121766e-01 4.9783710e-01 5.0512588e-01 4.9686161e-01 4.9527276e-01\n",
      " 4.9696052e-01 5.0275314e-01 5.0624770e-01 4.9570268e-01 5.0011384e-01\n",
      " 5.0269604e-01 5.0046551e-01 5.0117725e-01 4.9100143e-01 4.9886787e-01\n",
      " 4.9155200e-01]\n"
     ]
    }
   ],
   "source": [
    "print(y_true[2])\n",
    "print(y_pred[2])\n",
    "\n",
    "print((y_true[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mass_Spec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
