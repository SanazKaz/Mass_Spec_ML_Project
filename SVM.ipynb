{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "def load_data(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pkl.load(f)\n",
    "    return data\n",
    "\n",
    "# Load the data\n",
    "Interaction_matrices = load_data('interaction_matrices.pkl')\n",
    "spectral_data = load_data('spectra_dataset.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 6, 6])\n",
      "torch.Size([10000, 20000])\n"
     ]
    }
   ],
   "source": [
    "print(Interaction_matrices.shape)\n",
    "print(spectral_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 36])\n",
      "tensor([0., 0., 0., 5., 0., 0., 2., 0., 0., 0., 5., 0., 1., 0., 3., 2., 5., 5.,\n",
      "        2., 2., 1., 3., 0., 6., 0., 0., 3., 3., 1., 0., 0., 2., 0., 0., 5., 0.])\n",
      "torch.Size([10000, 20000])\n"
     ]
    }
   ],
   "source": [
    "# reshaping to flatten both piece of data\n",
    "\n",
    "Interaction_matrices_flattened =Interaction_matrices.reshape(Interaction_matrices.shape[0], -1)\n",
    "print(Interaction_matrices_flattened.shape)\n",
    "print(Interaction_matrices_flattened[0])\n",
    "\n",
    "spectral_data_flattened = spectral_data.reshape(10000, -1)\n",
    "print(spectral_data_flattened.shape) # no need to do this tbh since it's already flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8000, 20000])\n",
      "torch.Size([1000, 20000])\n",
      "torch.Size([1000, 20000])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "spec_train, spec_test, matrix_train, matrix_test = train_test_split(spectral_data_flattened, Interaction_matrices_flattened, test_size=0.2, random_state=42)\n",
    "spec_test, spec_val, matrix_test, matrix_val = train_test_split(spec_test, matrix_test, test_size=0.5, random_state=42)\n",
    "\n",
    "print(spec_train.shape)\n",
    "print(spec_test.shape)\n",
    "print(spec_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# pytorch dataset and loaders\n",
    "train_dataset = TensorDataset(torch.Tensor(spec_train), torch.Tensor(matrix_train))\n",
    "val_dataset = TensorDataset(torch.Tensor(spec_val), torch.Tensor(matrix_val))\n",
    "test_dataset = TensorDataset(torch.Tensor(spec_test), torch.Tensor(matrix_test))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# defining the SVM\n",
    "\n",
    "class SVMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SVMModel, self).__init__()\n",
    "        self.hidden1= nn.Linear(input_dim, hidden_dim)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.act2 = nn.ReLU() # added a bunch of hidden layers\n",
    "        self.hidden3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.act3 = nn.ReLU() # activation functions\n",
    "        self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = F.relu(self.hidden3(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8000, 20000])\n"
     ]
    }
   ],
   "source": [
    "print(spec_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 7.077150344848633\n",
      "Epoch 2/25, Loss: 7.041650772094727\n",
      "Epoch 3/25, Loss: 6.055182933807373\n",
      "Epoch 4/25, Loss: 4.757182598114014\n",
      "Epoch 5/25, Loss: 4.406103134155273\n",
      "Epoch 6/25, Loss: 4.44008207321167\n",
      "Epoch 7/25, Loss: 4.2076568603515625\n",
      "Epoch 8/25, Loss: 4.439328193664551\n",
      "Epoch 9/25, Loss: 4.605320930480957\n",
      "Epoch 10/25, Loss: 4.464384078979492\n",
      "Epoch 11/25, Loss: 4.423389434814453\n",
      "Epoch 12/25, Loss: 4.4784345626831055\n",
      "Epoch 13/25, Loss: 4.564752101898193\n",
      "Epoch 14/25, Loss: 4.405340671539307\n",
      "Epoch 15/25, Loss: 4.49427604675293\n",
      "Epoch 16/25, Loss: 4.460813522338867\n",
      "Epoch 17/25, Loss: 4.3172383308410645\n",
      "Epoch 18/25, Loss: 4.444540977478027\n",
      "Epoch 19/25, Loss: 4.444989204406738\n",
      "Epoch 20/25, Loss: 4.3337883949279785\n",
      "Epoch 21/25, Loss: 4.25850772857666\n",
      "Epoch 22/25, Loss: 4.342062950134277\n",
      "Epoch 23/25, Loss: 4.431821346282959\n",
      "Epoch 24/25, Loss: 4.44091272354126\n",
      "Epoch 25/25, Loss: 4.3321309089660645\n"
     ]
    }
   ],
   "source": [
    "input_dim = spectral_data_flattened.shape[1]\n",
    "hidden_dim = 128 # hyperparameter\n",
    "output_dim = Interaction_matrices_flattened.shape[1]\n",
    "model = SVMModel(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# defining the loss func tion and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001) # hyperparameter\n",
    "\n",
    "train_loss = 0\n",
    "num_epochs = 25 # hyperparameter\n",
    "for epoch in range(num_epochs):\n",
    "    for spec_train, matrix_train in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(spec_train)\n",
    "        loss = criterion(outputs, matrix_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "    #print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mass_Spec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
