{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from scipy.fft import fft\n",
    "import torch \n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "with open ('interaction_matrices.pkl', 'rb') as int_matrices:\n",
    "    interaction_matrices = pickle.load(int_matrices)\n",
    "\n",
    "with open ('spectra_dataset.pkl', 'rb') as spec_dataset:\n",
    "    spec_dataset = pickle.load(spec_dataset)\n",
    "\n",
    "\n",
    "# converting the dataset to numpy arrays\n",
    "\n",
    "interaction_matrices = interaction_matrices.numpy()\n",
    "spec_dataset = spec_dataset.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(spec_dataset.shape)\n",
    "print(interaction_matrices.shape)\n",
    "\n",
    "# data is in good shape \n",
    "# NMF Y ~ WH\n",
    "# Y is the dataset\n",
    "# W IS THE BASIS MATRIX AND H IS THE COEFFICIENT MATRIX\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.decomposition import NMF\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "selected_spec = spec_dataset[:10000,:]\n",
    "print(selected_spec.shape)\n",
    "\n",
    "model = NMF(n_components=75, init='nndsvd', random_state=40, max_iter=200, beta_loss='frobenius')\n",
    "W = model.fit_transform(selected_spec)\n",
    "H = model.components_\n",
    "\n",
    "approximation = np.dot(W,H)\n",
    "\n",
    "reconstruction_error = np.linalg.norm(selected_spec - approximation, 'fro')\n",
    "print(\"Forbenius norm error:\", reconstruction_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select a few spectra to plot\n",
    "spectra_indices = [5000]  # For example, the first, 11th, and 21st spectra\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for idx in spectra_indices:\n",
    "    plt.plot(selected_spec[idx, :], label=f'Original Spectrum {idx+1}')\n",
    "    plt.plot(approximation[idx, :], label=f'Reconstructed Spectrum {idx+1}', linestyle='--')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Comparison of Original and Reconstructed Spectra')\n",
    "plt.xlabel('m/z Values')\n",
    "plt.ylabel('Intensity')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(spec_dataset[5000,:])\n",
    "plt.title('Original Spectrum')  \n",
    "plt.xlabel('m/z Values')\n",
    "plt.ylabel('Intensity')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "torch.Size([10000, 6, 6])\n",
      "torch.Size([10000, 2000])\n",
      "torch.Size([10000, 36])\n",
      "tensor([[0., 4., 2., 0., 0., 0., 2., 5., 0., 0., 0., 3., 2., 2., 0., 1., 6., 0.,\n",
      "         4., 1., 4., 0., 6., 0., 0., 1., 1., 0., 0., 0., 5., 5., 0., 0., 0., 3.],\n",
      "        [0., 0., 0., 0., 6., 2., 4., 6., 4., 3., 0., 1., 0., 3., 2., 5., 6., 3.,\n",
      "         6., 1., 1., 0., 0., 0., 0., 0., 4., 6., 3., 0., 0., 0., 2., 6., 2., 3.],\n",
      "        [0., 0., 5., 5., 0., 0., 0., 0., 6., 6., 3., 2., 4., 0., 0., 4., 6., 0.,\n",
      "         6., 1., 0., 0., 1., 4., 0., 0., 2., 0., 0., 6., 2., 0., 2., 0., 1., 6.],\n",
      "        [0., 0., 0., 1., 6., 0., 0., 0., 3., 0., 0., 0., 2., 0., 3., 0., 0., 3.,\n",
      "         3., 0., 3., 0., 5., 6., 2., 3., 0., 0., 0., 4., 0., 0., 1., 0., 5., 0.],\n",
      "        [0., 3., 0., 5., 0., 3., 5., 0., 0., 2., 3., 0., 2., 6., 2., 4., 0., 0.,\n",
      "         3., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 2., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 5., 0., 2., 0., 0., 0., 1., 0., 3., 4., 0., 6., 0., 0.,\n",
      "         2., 3., 0., 5., 0., 0., 5., 0., 0., 0., 0., 1., 0., 3., 0., 0., 6., 0.],\n",
      "        [0., 0., 2., 0., 0., 4., 0., 0., 1., 0., 0., 0., 1., 2., 6., 0., 1., 0.,\n",
      "         0., 0., 0., 4., 0., 0., 0., 0., 0., 0., 0., 5., 0., 4., 0., 0., 6., 0.],\n",
      "        [0., 6., 0., 0., 0., 0., 0., 6., 0., 0., 0., 0., 6., 2., 0., 3., 4., 0.,\n",
      "         4., 0., 0., 5., 0., 0., 1., 0., 0., 0., 3., 1., 0., 6., 0., 0., 0., 6.],\n",
      "        [0., 5., 5., 0., 3., 1., 0., 5., 5., 0., 0., 5., 5., 3., 4., 0., 0., 5.,\n",
      "         1., 5., 6., 6., 0., 2., 0., 1., 0., 0., 3., 0., 0., 5., 3., 0., 0., 2.],\n",
      "        [0., 0., 0., 0., 6., 0., 0., 1., 5., 6., 0., 5., 6., 0., 0., 0., 0., 0.,\n",
      "         3., 0., 4., 6., 0., 3., 0., 3., 3., 0., 0., 4., 2., 0., 1., 5., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn   \n",
    "import time\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "def load_data(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pkl.load(f)\n",
    "    return data\n",
    "\n",
    "# Load the data\n",
    "Interaction_matrices = load_data('interaction_matrices_10binned.pkl')\n",
    "spectral_data = load_data('spectra_dataset_10binned.pkl')\n",
    "\n",
    "print(Interaction_matrices.shape)\n",
    "print(spectral_data.shape)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Flatten each matrix separately then store in an array\n",
    "flattened_matrices = [matrix.flatten() for matrix in Interaction_matrices]\n",
    "\n",
    "# Stack the flattened matrices on top to give shape N x 36\n",
    "flattened_matrix = torch.stack(flattened_matrices)\n",
    "print(flattened_matrix.shape)\n",
    "\n",
    "print(flattened_matrix[0:10]) ## fine. \n",
    "\n",
    "import torch \n",
    "import numpy\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "binary_flat_matrices = (flattened_matrix >= threshold).float()\n",
    "\n",
    "\n",
    "# making them flat instead of including \n",
    "# abundance as that is not important for now and requires more\n",
    "\n",
    "for matrix in binary_flat_matrices:\n",
    "  for i in range (len(matrix)):\n",
    "    value = matrix[i]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 6., 2., 4., 6., 4., 3., 0., 1., 0., 3., 2., 5., 6., 3.,\n",
      "        6., 1., 1., 0., 0., 0., 0., 0., 4., 6., 3., 0., 0., 0., 2., 6., 2., 3.])\n",
      "tensor([0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "(10000, 36)\n",
      "      PA0PB0  PA0PB1  PA0PB2  PA0PB3  PA0PB4  PA0PB5  PA1PB0  PA1PB1  PA1PB2  \\\n",
      "0        0.0     1.0     1.0     0.0     0.0     0.0     1.0     1.0     0.0   \n",
      "1        0.0     0.0     0.0     0.0     1.0     1.0     1.0     1.0     1.0   \n",
      "2        0.0     0.0     1.0     1.0     0.0     0.0     0.0     0.0     1.0   \n",
      "3        0.0     0.0     0.0     1.0     1.0     0.0     0.0     0.0     1.0   \n",
      "4        0.0     1.0     0.0     1.0     0.0     1.0     1.0     0.0     0.0   \n",
      "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "9995     0.0     1.0     0.0     1.0     0.0     1.0     0.0     0.0     0.0   \n",
      "9996     0.0     0.0     1.0     0.0     1.0     1.0     1.0     1.0     1.0   \n",
      "9997     0.0     1.0     0.0     0.0     1.0     0.0     1.0     0.0     0.0   \n",
      "9998     0.0     1.0     1.0     1.0     1.0     1.0     0.0     1.0     0.0   \n",
      "9999     0.0     0.0     0.0     1.0     0.0     1.0     1.0     1.0     0.0   \n",
      "\n",
      "      PA1PB3  ...  PA4PB2  PA4PB3  PA4PB4  PA4PB5  PA5PB0  PA5PB1  PA5PB2  \\\n",
      "0        0.0  ...     1.0     0.0     0.0     0.0     1.0     1.0     0.0   \n",
      "1        1.0  ...     1.0     1.0     1.0     0.0     0.0     0.0     1.0   \n",
      "2        1.0  ...     1.0     0.0     0.0     1.0     1.0     0.0     1.0   \n",
      "3        0.0  ...     0.0     0.0     0.0     1.0     0.0     0.0     1.0   \n",
      "4        1.0  ...     1.0     1.0     0.0     1.0     0.0     0.0     0.0   \n",
      "...      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "9995     1.0  ...     0.0     0.0     1.0     0.0     0.0     1.0     1.0   \n",
      "9996     1.0  ...     0.0     1.0     0.0     1.0     0.0     1.0     0.0   \n",
      "9997     0.0  ...     1.0     1.0     0.0     1.0     1.0     0.0     0.0   \n",
      "9998     1.0  ...     0.0     1.0     0.0     1.0     0.0     1.0     0.0   \n",
      "9999     1.0  ...     0.0     0.0     1.0     1.0     0.0     0.0     0.0   \n",
      "\n",
      "      PA5PB3  PA5PB4  PA5PB5  \n",
      "0        0.0     0.0     1.0  \n",
      "1        1.0     1.0     1.0  \n",
      "2        0.0     1.0     1.0  \n",
      "3        0.0     1.0     0.0  \n",
      "4        0.0     0.0     0.0  \n",
      "...      ...     ...     ...  \n",
      "9995     0.0     1.0     0.0  \n",
      "9996     0.0     0.0     0.0  \n",
      "9997     1.0     0.0     1.0  \n",
      "9998     1.0     0.0     0.0  \n",
      "9999     0.0     0.0     1.0  \n",
      "\n",
      "[10000 rows x 36 columns]\n",
      "(10000, 2000)\n"
     ]
    }
   ],
   "source": [
    "print(flattened_matrix[1])\n",
    "print(binary_flat_matrices[1])\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# need to turn tensors to pandas df then append my flattened matrices to the end.\n",
    "matrix_columns = [f'PA{i // 6}PB{i % 6}' for i in range(len(flattened_matrices[0]))]\n",
    "\n",
    "bnry_int_mat_df = pd.DataFrame(binary_flat_matrices, columns = matrix_columns)\n",
    "print(bnry_int_mat_df.shape)\n",
    "print(bnry_int_mat_df)\n",
    "spec_df = pd.DataFrame(spectral_data)\n",
    "print(spec_df.shape)\n",
    "\n",
    "# next  concat the two together \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "concat_df = pd.concat([spec_df, bnry_int_mat_df], axis =1)\n",
    "\n",
    "#Â pre process data some more\n",
    "\n",
    "X_spec = concat_df.iloc[:, :2000].values # spectra data\n",
    "Y_matr = concat_df.iloc[:, 2000:].values # matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# splitting into train test val split 80, 20 \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_spec, Y_matr, test_size=0.2, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: (10000, 2000) torch.Size([8000, 36])\n",
      "Validation Set: torch.Size([400, 2000]) torch.Size([400, 36])\n",
      "Test Set: torch.Size([1600, 2000]) torch.Size([1600, 36])\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set:\", X_spec.shape, y_train.shape)\n",
    "print(\"Validation Set:\", X_val.shape, y_val.shape)\n",
    "print(\"Test Set:\", X_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "import torch \n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train = torch.Tensor(X_train).to(device)\n",
    "X_test = torch.Tensor(X_test).to(device)\n",
    "X_val = torch.Tensor(X_val).to(device)\n",
    "y_val= torch.Tensor(y_val).to(device)\n",
    "y_train = torch.Tensor(y_train).to(device)\n",
    "y_test = torch.Tensor(y_test).to(device)\n",
    "\n",
    "\n",
    "batch_size = 512\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 2000]) torch.Size([512, 36])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "seed = 42  # Choose any integer value as the seed\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "class SpectralCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SpectralCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 250, 128)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpectralCNN(num_classes=36).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpectralCNN(\n",
      "  (conv1): Conv1d(1, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (relu2): ReLU()\n",
      "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (relu3): ReLU()\n",
      "  (pool3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=16000, out_features=128, bias=True)\n",
      "  (relu4): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=128, out_features=36, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_losses = []\n",
    "epoch_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.6879, Accuracy: 0.00%\n",
      "Epoch [2/100], Loss: 0.6836, Accuracy: 0.00%\n",
      "Epoch [3/100], Loss: 0.6814, Accuracy: 0.00%\n",
      "Epoch [4/100], Loss: 0.6802, Accuracy: 0.00%\n",
      "Epoch [5/100], Loss: 0.6789, Accuracy: 0.00%\n",
      "Epoch [6/100], Loss: 0.6781, Accuracy: 0.00%\n",
      "Epoch [7/100], Loss: 0.6770, Accuracy: 0.00%\n",
      "Epoch [8/100], Loss: 0.6765, Accuracy: 0.00%\n",
      "Epoch [9/100], Loss: 0.6759, Accuracy: 0.00%\n",
      "Epoch [10/100], Loss: 0.6755, Accuracy: 0.00%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [11/100], Loss: 0.6751, Accuracy: 0.00%\n",
      "Epoch [12/100], Loss: 0.6751, Accuracy: 0.00%\n",
      "Epoch [13/100], Loss: 0.6748, Accuracy: 0.00%\n",
      "Epoch [14/100], Loss: 0.6746, Accuracy: 0.00%\n",
      "Epoch [15/100], Loss: 0.6746, Accuracy: 0.00%\n",
      "Epoch [16/100], Loss: 0.6745, Accuracy: 0.00%\n",
      "Epoch [17/100], Loss: 0.6745, Accuracy: 0.00%\n",
      "Epoch [18/100], Loss: 0.6745, Accuracy: 0.00%\n",
      "Epoch [19/100], Loss: 0.6744, Accuracy: 0.00%\n",
      "Epoch [20/100], Loss: 0.6744, Accuracy: 0.00%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [21/100], Loss: 0.6743, Accuracy: 0.00%\n",
      "Epoch [22/100], Loss: 0.6744, Accuracy: 0.00%\n",
      "Epoch [23/100], Loss: 0.6743, Accuracy: 0.00%\n",
      "Epoch [24/100], Loss: 0.6743, Accuracy: 0.00%\n",
      "Epoch [25/100], Loss: 0.6742, Accuracy: 0.00%\n",
      "Epoch [26/100], Loss: 0.6743, Accuracy: 0.00%\n",
      "Epoch [27/100], Loss: 0.6743, Accuracy: 0.00%\n",
      "Epoch [28/100], Loss: 0.6743, Accuracy: 0.00%\n",
      "Epoch [29/100], Loss: 0.6743, Accuracy: 0.00%\n",
      "Epoch [30/100], Loss: 0.6742, Accuracy: 0.00%\n",
      "Saved model to: spectral_net_model.pth\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m batch_data, batch_labels \u001b[38;5;241m=\u001b[39m batch_data\u001b[38;5;241m.\u001b[39mto(device), batch_labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_labels)\n\u001b[1;32m     15\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/Mass_Spec/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Mass_Spec/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[21], line 37\u001b[0m, in \u001b[0;36mSpectralCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu2(x)\n\u001b[1;32m     35\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool2(x)\n\u001b[0;32m---> 37\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu3(x)\n\u001b[1;32m     39\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool3(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/Mass_Spec/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Mass_Spec/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Mass_Spec/lib/python3.11/site-packages/torch/nn/modules/conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Mass_Spec/lib/python3.11/site-packages/torch/nn/modules/conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch_data, batch_labels in train_loader:\n",
    "        batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_data)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        predictions = outputs.detach() >= 0.5\n",
    "        accuracy = torch.mean(torch.all(predictions == batch_labels, dim=1).float())\n",
    "        epoch_accuracy += accuracy.item()\n",
    "\n",
    "    epoch_loss /= len(train_loader)\n",
    "    epoch_losses.append(epoch_loss)\n",
    "    epoch_accuracy /= len(train_loader)\n",
    "    epoch_accuracies.append(epoch_accuracy)\n",
    "\n",
    "\n",
    "    # Print the loss and accuracy every 100 epochs\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "     \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save(model.state_dict(), \"spectral_net_model.pth\") ## save the model every 100 epochs\n",
    "        print(\"Saved model to:\", \"spectral_net_model.pth\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SpectraMatrixNet.forward() missing 1 required positional argument: 'matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# No need to track gradients during validation\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m spectra_val, matrix_val \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[0;32m---> 15\u001b[0m         predicted_matrices \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspectra_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(predicted_matrices, matrix_val)\n\u001b[1;32m     17\u001b[0m         validation_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/Mass_Spec/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Mass_Spec/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: SpectraMatrixNet.forward() missing 1 required positional argument: 'matrix'"
     ]
    }
   ],
   "source": [
    "def accuracy(predicted, target):\n",
    "    \"\"\"supposedly checks accuracy but dont think it works for this case\"\"\"\n",
    "    return torch.mean((predicted == target).float())\n",
    "\n",
    "torch.load('best_model_weights_softplus.pt')\n",
    "\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "validation_loss = 0.0\n",
    "val_accuracy = 0.0\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "with torch.no_grad():  # No need to track gradients during validation\n",
    "    for spectra_val, matrix_val in val_loader:\n",
    "        predicted_matrices = model(spectra_val)\n",
    "        loss = criterion(predicted_matrices, matrix_val)\n",
    "        validation_loss += loss.item()\n",
    "        val_accuracy += accuracy(predicted_matrices, matrix_val)\n",
    "\n",
    "loss /= len(val_loader)\n",
    "val_accuracy += accuracy(predicted_matrices, matrix_val)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate average loss over all validation batches\n",
    "average_validation_loss = validation_loss / len(val_loader)\n",
    "print(f'Average Validation Loss: {average_validation_loss}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "print(f\"Predicted matrix shape: {predicted_matrices.shape}\")\n",
    "print(f\"Target matrix shape: {matrix_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Px: tensor([[0., 2., 0., 2., 1., 3.],\n",
      "        [0., 5., 4., 0., 0., 3.],\n",
      "        [0., 0., 0., 5., 6., 0.],\n",
      "        [4., 0., 1., 2., 0., 3.],\n",
      "        [0., 5., 4., 0., 0., 5.],\n",
      "        [6., 0., 0., 1., 5., 5.]])\n",
      "Tx: tensor([[0., 2., 0., 3., 1., 3.],\n",
      "        [0., 5., 4., 0., 0., 3.],\n",
      "        [0., 0., 0., 5., 6., 0.],\n",
      "        [4., 0., 1., 2., 0., 3.],\n",
      "        [0., 5., 4., 0., 0., 5.],\n",
      "        [6., 0., 0., 1., 5., 5.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Px: {torch.round(predicted_matrices[1])}\")\n",
    "print(f\"Tx: {matrix_val[1]}\")\n",
    "\n",
    "\n",
    "torch.equal(torch.round(predicted_matrices[1]), matrix_val[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x3266c6690>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(predicted_matrices[6].detach().numpy())\n",
    "plt.matshow(matrix_val[6].detach().numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Couple things to do - need to go back to Y=W.H and make sure that when shuffeling that H attahced so that i can go back to the actual spectra also. Then can actually check the spectra\n",
    "\n",
    "nevermind. i gave themodel with answers lol\n",
    "\n",
    "moving on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn.functional as Fun\n",
    "A = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "output = Fun.one_hot(A)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mass_Spec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
