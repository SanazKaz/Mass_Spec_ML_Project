{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 6, 6])\n",
      "torch.Size([10000, 20000])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "def load_data(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pkl.load(f)\n",
    "    return data\n",
    "\n",
    "# Load the data\n",
    "Interaction_matrices = load_data('interaction_matrices.pkl')\n",
    "spectral_data = load_data('spectra_dataset.pkl')\n",
    "\n",
    "print(Interaction_matrices.shape)\n",
    "print(spectral_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/02/fvfmdq_j709g1tthj47t5fcm0000gn/T/ipykernel_18909/1288698792.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spectral_data_tensor = torch.tensor(spectral_data.unsqueeze(-1), dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4000, 20000, 1])\n",
      "torch.Size([4000, 36])\n",
      "torch.Size([10000, 36])\n",
      "torch.Size([10000, 20000, 1])\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/02/fvfmdq_j709g1tthj47t5fcm0000gn/T/ipykernel_18909/1288698792.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  matrices_tensor = torch.tensor(Interaction_matrices.view(-1, 36), dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# reshaping for LSTM - added one dimension at the end\n",
    "spectral_data_tensor = torch.tensor(spectral_data.unsqueeze(-1), dtype=torch.float32)\n",
    "matrices_tensor = torch.tensor(Interaction_matrices.view(-1, 36), dtype=torch.float32)\n",
    "\n",
    "new_tensor = spectral_data_tensor[:4000]\n",
    "new_matrices = matrices_tensor[:4000]\n",
    "print(new_tensor.shape)\n",
    "print(new_matrices.shape)\n",
    "\n",
    "print(matrices_tensor.shape)\n",
    "print(spectral_data_tensor.shape)\n",
    "\n",
    "print(spectral_data.dtype)\n",
    "print(Interaction_matrices.dtype)\n",
    "\n",
    "# already float32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3200, 20000, 1])\n",
      "torch.Size([400, 20000, 1])\n",
      "torch.Size([400, 20000, 1])\n",
      "torch.Size([3200, 36])\n",
      "torch.Size([400, 36])\n",
      "torch.Size([400, 36])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "spec_train, spec_test, matrix_train, matrix_test = train_test_split(new_tensor, new_matrices, test_size=0.2, random_state=42)\n",
    "spec_test, spec_val, matrix_test, matrix_val = train_test_split(spec_test, matrix_test, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "# reshaped for LSTM\n",
    "print(spec_train.shape)\n",
    "print(spec_test.shape)\n",
    "print(spec_val.shape)\n",
    "\n",
    "print(matrix_train.shape)\n",
    "print(matrix_test.shape)\n",
    "print(matrix_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "# pytorch dataset and loaders\n",
    "train_dataset = TensorDataset(torch.Tensor(spec_train), torch.Tensor(matrix_train))\n",
    "val_dataset = TensorDataset(torch.Tensor(spec_val), torch.Tensor(matrix_val))\n",
    "test_dataset = TensorDataset(torch.Tensor(spec_test), torch.Tensor(matrix_test))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 20000, 1])\n",
      "torch.Size([64, 36])\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(data[0].shape)\n",
    "    print(data[1].shape)\n",
    "    print(batch_size)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn   \n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=64, num_layers=2, batch_first=True)\n",
    "        self.regressor = nn.Linear(64, 36)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # forward passing\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "\n",
    "        # only last time step\n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "\n",
    "        # pass output to lstm to fully connected later to predict all 36 values\n",
    "        output = self.regressor(lstm_out)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "model = LSTM()\n",
    "\n",
    "criteria = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msanazkazeminia97\u001b[0m (\u001b[33msanaz_team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sanazkazeminia/Documents/Mass_Spec_project/Mass_Spec_ML_Project/wandb/run-20240425_160044-gy8b0r5t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sanaz_team/my-awesome-project/runs/gy8b0r5t' target=\"_blank\">prime-capybara-9</a></strong> to <a href='https://wandb.ai/sanaz_team/my-awesome-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sanaz_team/my-awesome-project' target=\"_blank\">https://wandb.ai/sanaz_team/my-awesome-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sanaz_team/my-awesome-project/runs/gy8b0r5t' target=\"_blank\">https://wandb.ai/sanaz_team/my-awesome-project/runs/gy8b0r5t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside the loop\n",
      "started at Thu Apr 25 16:00:47 2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-04-25 16:00:47 18909:7383288 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"my-awesome-project\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"architecture\": \"LSTM\",\n",
    "    \"dataset\": \"4000-part-spectra\",\n",
    "    \"epochs\": 10,\n",
    "    }\n",
    ")\n",
    "\n",
    "def train_model(model, data_loader, criterion, optimizer, epochs):\n",
    "    model.train()\n",
    "    with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "        for epoch in range(epochs):\n",
    "            print(\"inside the loop\")\n",
    "            print(f\"started at {time.ctime()}\")\n",
    "            total_loss = 0\n",
    "            for spectra, labels in data_loader:\n",
    "                optimizer.zero_grad()\n",
    "                with record_function(\"model_forward\"):\n",
    "                    output = model(spectra)\n",
    "                with record_function(\"calc_loss\"):\n",
    "                    loss = criterion(output, labels)\n",
    "                with record_function(\"backprop\"):\n",
    "                    loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item() * spectra.size(0)\n",
    "            \n",
    "            print(f'Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(data_loader.dataset)}')\n",
    "            print(f\"ended at {time.ctime()}\")\n",
    "    print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "\n",
    "train_model(model, train_loader, criteria, optimizer, epochs=10)\n",
    "\n",
    "# 2m22seconds for 800 dataset epoch 1 batch size 32 total loss ~6.5 lr = 0.001\n",
    "# 2m22seconds for 800 dataset epoch 1 batch size 64 loss ~7.196 lr = 0.001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mass_Spec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
