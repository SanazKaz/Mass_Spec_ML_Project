{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "torch.Size([10000, 6, 6])\n",
      "torch.Size([10000, 2000])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn   \n",
    "import time\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "def load_data(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pkl.load(f)\n",
    "    return data\n",
    "\n",
    "# Load the data\n",
    "Interaction_matrices = load_data('interaction_matrices_10binned.pkl')\n",
    "spectral_data = load_data('spectra_dataset_10binned.pkl')\n",
    "\n",
    "print(Interaction_matrices.shape)\n",
    "print(spectral_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 36])\n",
      "tensor([[0., 4., 2., 0., 0., 0., 2., 5., 0., 0., 0., 3., 2., 2., 0., 1., 6., 0.,\n",
      "         4., 1., 4., 0., 6., 0., 0., 1., 1., 0., 0., 0., 5., 5., 0., 0., 0., 3.],\n",
      "        [0., 0., 0., 0., 6., 2., 4., 6., 4., 3., 0., 1., 0., 3., 2., 5., 6., 3.,\n",
      "         6., 1., 1., 0., 0., 0., 0., 0., 4., 6., 3., 0., 0., 0., 2., 6., 2., 3.],\n",
      "        [0., 0., 5., 5., 0., 0., 0., 0., 6., 6., 3., 2., 4., 0., 0., 4., 6., 0.,\n",
      "         6., 1., 0., 0., 1., 4., 0., 0., 2., 0., 0., 6., 2., 0., 2., 0., 1., 6.],\n",
      "        [0., 0., 0., 1., 6., 0., 0., 0., 3., 0., 0., 0., 2., 0., 3., 0., 0., 3.,\n",
      "         3., 0., 3., 0., 5., 6., 2., 3., 0., 0., 0., 4., 0., 0., 1., 0., 5., 0.],\n",
      "        [0., 3., 0., 5., 0., 3., 5., 0., 0., 2., 3., 0., 2., 6., 2., 4., 0., 0.,\n",
      "         3., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 2., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 5., 0., 2., 0., 0., 0., 1., 0., 3., 4., 0., 6., 0., 0.,\n",
      "         2., 3., 0., 5., 0., 0., 5., 0., 0., 0., 0., 1., 0., 3., 0., 0., 6., 0.],\n",
      "        [0., 0., 2., 0., 0., 4., 0., 0., 1., 0., 0., 0., 1., 2., 6., 0., 1., 0.,\n",
      "         0., 0., 0., 4., 0., 0., 0., 0., 0., 0., 0., 5., 0., 4., 0., 0., 6., 0.],\n",
      "        [0., 6., 0., 0., 0., 0., 0., 6., 0., 0., 0., 0., 6., 2., 0., 3., 4., 0.,\n",
      "         4., 0., 0., 5., 0., 0., 1., 0., 0., 0., 3., 1., 0., 6., 0., 0., 0., 6.],\n",
      "        [0., 5., 5., 0., 3., 1., 0., 5., 5., 0., 0., 5., 5., 3., 4., 0., 0., 5.,\n",
      "         1., 5., 6., 6., 0., 2., 0., 1., 0., 0., 3., 0., 0., 5., 3., 0., 0., 2.],\n",
      "        [0., 0., 0., 0., 6., 0., 0., 1., 5., 6., 0., 5., 6., 0., 0., 0., 0., 0.,\n",
      "         3., 0., 4., 6., 0., 3., 0., 3., 3., 0., 0., 4., 2., 0., 1., 5., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Flatten each matrix separately then store in an array\n",
    "flattened_matrices = [matrix.flatten() for matrix in Interaction_matrices]\n",
    "\n",
    "# Stack the flattened matrices on top to give shape N x 36\n",
    "flattened_matrix = torch.stack(flattened_matrices)\n",
    "print(flattened_matrix.shape)\n",
    "\n",
    "print(flattened_matrix[0:10]) ## fine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "binary_flat_matrices = (flattened_matrix >= threshold).float()\n",
    "\n",
    "\n",
    "# making them flat instead of including \n",
    "# abundance as that is not important for now and requires more\n",
    "\n",
    "for matrix in binary_flat_matrices:\n",
    "  for i in range (len(matrix)):\n",
    "    value = matrix[i]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 6., 2., 4., 6., 4., 3., 0., 1., 0., 3., 2., 5., 6., 3.,\n",
      "        6., 1., 1., 0., 0., 0., 0., 0., 4., 6., 3., 0., 0., 0., 2., 6., 2., 3.])\n",
      "tensor([0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "print(flattened_matrix[1])\n",
    "print(binary_flat_matrices[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 36)\n",
      "      PA0PB0  PA0PB1  PA0PB2  PA0PB3  PA0PB4  PA0PB5  PA1PB0  PA1PB1  PA1PB2  \\\n",
      "0        0.0     1.0     1.0     0.0     0.0     0.0     1.0     1.0     0.0   \n",
      "1        0.0     0.0     0.0     0.0     1.0     1.0     1.0     1.0     1.0   \n",
      "2        0.0     0.0     1.0     1.0     0.0     0.0     0.0     0.0     1.0   \n",
      "3        0.0     0.0     0.0     1.0     1.0     0.0     0.0     0.0     1.0   \n",
      "4        0.0     1.0     0.0     1.0     0.0     1.0     1.0     0.0     0.0   \n",
      "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "9995     0.0     1.0     0.0     1.0     0.0     1.0     0.0     0.0     0.0   \n",
      "9996     0.0     0.0     1.0     0.0     1.0     1.0     1.0     1.0     1.0   \n",
      "9997     0.0     1.0     0.0     0.0     1.0     0.0     1.0     0.0     0.0   \n",
      "9998     0.0     1.0     1.0     1.0     1.0     1.0     0.0     1.0     0.0   \n",
      "9999     0.0     0.0     0.0     1.0     0.0     1.0     1.0     1.0     0.0   \n",
      "\n",
      "      PA1PB3  ...  PA4PB2  PA4PB3  PA4PB4  PA4PB5  PA5PB0  PA5PB1  PA5PB2  \\\n",
      "0        0.0  ...     1.0     0.0     0.0     0.0     1.0     1.0     0.0   \n",
      "1        1.0  ...     1.0     1.0     1.0     0.0     0.0     0.0     1.0   \n",
      "2        1.0  ...     1.0     0.0     0.0     1.0     1.0     0.0     1.0   \n",
      "3        0.0  ...     0.0     0.0     0.0     1.0     0.0     0.0     1.0   \n",
      "4        1.0  ...     1.0     1.0     0.0     1.0     0.0     0.0     0.0   \n",
      "...      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "9995     1.0  ...     0.0     0.0     1.0     0.0     0.0     1.0     1.0   \n",
      "9996     1.0  ...     0.0     1.0     0.0     1.0     0.0     1.0     0.0   \n",
      "9997     0.0  ...     1.0     1.0     0.0     1.0     1.0     0.0     0.0   \n",
      "9998     1.0  ...     0.0     1.0     0.0     1.0     0.0     1.0     0.0   \n",
      "9999     1.0  ...     0.0     0.0     1.0     1.0     0.0     0.0     0.0   \n",
      "\n",
      "      PA5PB3  PA5PB4  PA5PB5  \n",
      "0        0.0     0.0     1.0  \n",
      "1        1.0     1.0     1.0  \n",
      "2        0.0     1.0     1.0  \n",
      "3        0.0     1.0     0.0  \n",
      "4        0.0     0.0     0.0  \n",
      "...      ...     ...     ...  \n",
      "9995     0.0     1.0     0.0  \n",
      "9996     0.0     0.0     0.0  \n",
      "9997     1.0     0.0     1.0  \n",
      "9998     1.0     0.0     0.0  \n",
      "9999     0.0     0.0     1.0  \n",
      "\n",
      "[10000 rows x 36 columns]\n",
      "(10000, 2000)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# need to turn tensors to pandas df then append my flattened matrices to the end.\n",
    "matrix_columns = [f'PA{i // 6}PB{i % 6}' for i in range(len(flattened_matrices[0]))]\n",
    "\n",
    "bnry_int_mat_df = pd.DataFrame(binary_flat_matrices, columns = matrix_columns)\n",
    "print(bnry_int_mat_df.shape)\n",
    "print(bnry_int_mat_df)\n",
    "spec_df = pd.DataFrame(spectral_data)\n",
    "print(spec_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next  concat the two together \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "concat_df = pd.concat([spec_df, bnry_int_mat_df], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2036)\n",
      "        0    1    2    3    4    5    6    7    8    9  ...  PA4PB2  PA4PB3  \\\n",
      "9000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     1.0   \n",
      "9001  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     1.0   \n",
      "9002  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     1.0     0.0   \n",
      "9003  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
      "9004  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     1.0   \n",
      "9005  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     1.0     0.0   \n",
      "9006  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     1.0   \n",
      "9007  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     1.0     0.0   \n",
      "9008  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     1.0   \n",
      "9009  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     1.0     1.0   \n",
      "\n",
      "      PA4PB4  PA4PB5  PA5PB0  PA5PB1  PA5PB2  PA5PB3  PA5PB4  PA5PB5  \n",
      "9000     0.0     1.0     0.0     1.0     1.0     0.0     1.0     1.0  \n",
      "9001     0.0     1.0     1.0     0.0     1.0     0.0     0.0     1.0  \n",
      "9002     0.0     0.0     0.0     1.0     0.0     0.0     1.0     0.0  \n",
      "9003     0.0     0.0     1.0     1.0     0.0     0.0     1.0     0.0  \n",
      "9004     1.0     1.0     0.0     0.0     0.0     0.0     1.0     0.0  \n",
      "9005     0.0     1.0     1.0     1.0     0.0     1.0     0.0     0.0  \n",
      "9006     0.0     0.0     0.0     1.0     0.0     1.0     1.0     0.0  \n",
      "9007     1.0     1.0     1.0     1.0     1.0     0.0     0.0     1.0  \n",
      "9008     1.0     0.0     1.0     0.0     0.0     1.0     1.0     1.0  \n",
      "9009     1.0     0.0     0.0     0.0     1.0     0.0     1.0     1.0  \n",
      "\n",
      "[10 rows x 2036 columns]\n"
     ]
    }
   ],
   "source": [
    "print(concat_df.shape)\n",
    "print(concat_df[9000:9010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat_df.to_csv(\"binned_by_10_labelled_ANN.csv\") # save the data to a csv file.  but its too big lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/02/fvfmdq_j709g1tthj47t5fcm0000gn/T/ipykernel_76017/3448698407.py:7: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  display.set_matplotlib_formats('svg')\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre process data some more\n",
    "  \n",
    "X_spec = concat_df.iloc[:, :2000].values # spectra data\n",
    "Y_matr = concat_df.iloc[:, 2000:].values # matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# splitting into train test val split 80, 20 \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_spec, Y_matr, test_size=0.2, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train = torch.Tensor(X_train).to(device)\n",
    "X_test = torch.Tensor(X_test).to(device)\n",
    "X_val = torch.Tensor(X_val).to(device)\n",
    "y_val= torch.Tensor(y_val).to(device)\n",
    "y_train = torch.Tensor(y_train).to(device)\n",
    "y_test = torch.Tensor(y_test).to(device)\n",
    "\n",
    "\n",
    "batch_size = 256 ## 512 is a good number for now. ?? 256 also worked well.\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8000, 2000])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) # confirmed shape 8000,2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpectralNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2000, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),  # Added layer\n",
    "            nn.ReLU(),  # Added activation function\n",
    "            nn.Linear(128, 36),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "model = SpectralNet().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#scheduler = ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.5, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpectralNet(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=2000, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=128, out_features=36, bias=True)\n",
      "    (9): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "import os\n",
    "## reloading saved model\n",
    "\n",
    "if os.path.exists(\"spectral_net_model.pth\"):\n",
    "    model.load_state_dict(torch.load(\"spectral_net_model.pth\"))\n",
    "    print(\"Model loaded\")\n",
    "    new_model = SpectralNet().to(device)  ## has to have the same arch.\n",
    "    new_model.load_state_dict(torch.load(\"spectral_net_model.pth\")) ## load the model\n",
    "    new_model.eval() ## set to eval mode optional\n",
    "else:\n",
    "    print(\"Model not loaded\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "epoch_losses = []\n",
    "epoch_accuracies = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/3000], Loss: 0.6134, Accuracy: 0.00%\n",
      "Epoch [20/3000], Loss: 0.6049, Accuracy: 0.00%\n",
      "Epoch [30/3000], Loss: 0.5979, Accuracy: 0.00%\n",
      "Epoch [40/3000], Loss: 0.5900, Accuracy: 0.00%\n",
      "Epoch [50/3000], Loss: 0.5834, Accuracy: 0.00%\n",
      "Epoch [60/3000], Loss: 0.5764, Accuracy: 0.00%\n",
      "Epoch [70/3000], Loss: 0.5692, Accuracy: 0.00%\n",
      "Epoch [80/3000], Loss: 0.5629, Accuracy: 0.00%\n",
      "Epoch [90/3000], Loss: 0.5565, Accuracy: 0.00%\n",
      "Epoch [100/3000], Loss: 0.5492, Accuracy: 0.00%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [110/3000], Loss: 0.5434, Accuracy: 0.00%\n",
      "Epoch [120/3000], Loss: 0.5368, Accuracy: 0.00%\n",
      "Epoch [130/3000], Loss: 0.5311, Accuracy: 0.00%\n",
      "Epoch [140/3000], Loss: 0.5240, Accuracy: 0.00%\n",
      "Epoch [150/3000], Loss: 0.5179, Accuracy: 0.00%\n",
      "Epoch [160/3000], Loss: 0.5124, Accuracy: 0.00%\n",
      "Epoch [170/3000], Loss: 0.5058, Accuracy: 0.00%\n",
      "Epoch [180/3000], Loss: 0.4998, Accuracy: 0.00%\n",
      "Epoch [190/3000], Loss: 0.4955, Accuracy: 0.00%\n",
      "Epoch [200/3000], Loss: 0.4882, Accuracy: 0.00%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [210/3000], Loss: 0.4825, Accuracy: 0.00%\n",
      "Epoch [220/3000], Loss: 0.4805, Accuracy: 0.00%\n",
      "Epoch [230/3000], Loss: 0.4728, Accuracy: 0.00%\n",
      "Epoch [240/3000], Loss: 0.4673, Accuracy: 0.00%\n",
      "Epoch [250/3000], Loss: 0.4619, Accuracy: 0.00%\n",
      "Epoch [260/3000], Loss: 0.4552, Accuracy: 0.00%\n",
      "Epoch [270/3000], Loss: 0.4514, Accuracy: 0.00%\n",
      "Epoch [280/3000], Loss: 0.4455, Accuracy: 0.00%\n",
      "Epoch [290/3000], Loss: 0.4407, Accuracy: 0.00%\n",
      "Epoch [300/3000], Loss: 0.4352, Accuracy: 0.00%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [310/3000], Loss: 0.4296, Accuracy: 0.00%\n",
      "Epoch [320/3000], Loss: 0.4248, Accuracy: 0.00%\n",
      "Epoch [330/3000], Loss: 0.4202, Accuracy: 0.00%\n",
      "Epoch [340/3000], Loss: 0.4163, Accuracy: 0.00%\n",
      "Epoch [350/3000], Loss: 0.4109, Accuracy: 0.00%\n",
      "Epoch [360/3000], Loss: 0.4070, Accuracy: 0.00%\n",
      "Epoch [370/3000], Loss: 0.4032, Accuracy: 0.00%\n",
      "Epoch [380/3000], Loss: 0.3964, Accuracy: 0.00%\n",
      "Epoch [390/3000], Loss: 0.3917, Accuracy: 0.00%\n",
      "Epoch [400/3000], Loss: 0.3877, Accuracy: 0.01%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [410/3000], Loss: 0.3831, Accuracy: 0.01%\n",
      "Epoch [420/3000], Loss: 0.3813, Accuracy: 0.01%\n",
      "Epoch [430/3000], Loss: 0.3753, Accuracy: 0.01%\n",
      "Epoch [440/3000], Loss: 0.3712, Accuracy: 0.01%\n",
      "Epoch [450/3000], Loss: 0.3679, Accuracy: 0.01%\n",
      "Epoch [460/3000], Loss: 0.3716, Accuracy: 0.01%\n",
      "Epoch [470/3000], Loss: 0.3605, Accuracy: 0.01%\n",
      "Epoch [480/3000], Loss: 0.3571, Accuracy: 0.01%\n",
      "Epoch [490/3000], Loss: 0.3526, Accuracy: 0.01%\n",
      "Epoch [500/3000], Loss: 0.3477, Accuracy: 0.01%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [510/3000], Loss: 0.3454, Accuracy: 0.01%\n",
      "Epoch [520/3000], Loss: 0.3407, Accuracy: 0.01%\n",
      "Epoch [530/3000], Loss: 0.3378, Accuracy: 0.01%\n",
      "Epoch [540/3000], Loss: 0.3357, Accuracy: 0.01%\n",
      "Epoch [550/3000], Loss: 0.3309, Accuracy: 0.01%\n",
      "Epoch [560/3000], Loss: 0.3270, Accuracy: 0.01%\n",
      "Epoch [570/3000], Loss: 0.3242, Accuracy: 0.01%\n",
      "Epoch [580/3000], Loss: 0.3228, Accuracy: 0.01%\n",
      "Epoch [590/3000], Loss: 0.3246, Accuracy: 0.01%\n",
      "Epoch [600/3000], Loss: 0.3146, Accuracy: 0.02%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [610/3000], Loss: 0.3165, Accuracy: 0.02%\n",
      "Epoch [620/3000], Loss: 0.3076, Accuracy: 0.02%\n",
      "Epoch [630/3000], Loss: 0.3085, Accuracy: 0.02%\n",
      "Epoch [640/3000], Loss: 0.3113, Accuracy: 0.02%\n",
      "Epoch [650/3000], Loss: 0.3026, Accuracy: 0.02%\n",
      "Epoch [660/3000], Loss: 0.3010, Accuracy: 0.02%\n",
      "Epoch [670/3000], Loss: 0.2980, Accuracy: 0.02%\n",
      "Epoch [680/3000], Loss: 0.2975, Accuracy: 0.02%\n",
      "Epoch [690/3000], Loss: 0.2931, Accuracy: 0.03%\n",
      "Epoch [700/3000], Loss: 0.2964, Accuracy: 0.02%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [710/3000], Loss: 0.2867, Accuracy: 0.03%\n",
      "Epoch [720/3000], Loss: 0.2846, Accuracy: 0.03%\n",
      "Epoch [730/3000], Loss: 0.2788, Accuracy: 0.03%\n",
      "Epoch [740/3000], Loss: 0.2834, Accuracy: 0.03%\n",
      "Epoch [750/3000], Loss: 0.2805, Accuracy: 0.03%\n",
      "Epoch [760/3000], Loss: 0.2762, Accuracy: 0.03%\n",
      "Epoch [770/3000], Loss: 0.2739, Accuracy: 0.03%\n",
      "Epoch [780/3000], Loss: 0.2714, Accuracy: 0.03%\n",
      "Epoch [790/3000], Loss: 0.2676, Accuracy: 0.04%\n",
      "Epoch [800/3000], Loss: 0.2682, Accuracy: 0.04%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [810/3000], Loss: 0.2623, Accuracy: 0.04%\n",
      "Epoch [820/3000], Loss: 0.2699, Accuracy: 0.03%\n",
      "Epoch [830/3000], Loss: 0.2581, Accuracy: 0.04%\n",
      "Epoch [840/3000], Loss: 0.2618, Accuracy: 0.04%\n",
      "Epoch [850/3000], Loss: 0.2548, Accuracy: 0.05%\n",
      "Epoch [860/3000], Loss: 0.2562, Accuracy: 0.04%\n",
      "Epoch [870/3000], Loss: 0.2496, Accuracy: 0.05%\n",
      "Epoch [880/3000], Loss: 0.2568, Accuracy: 0.04%\n",
      "Epoch [890/3000], Loss: 0.2485, Accuracy: 0.05%\n",
      "Epoch [900/3000], Loss: 0.2509, Accuracy: 0.05%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [910/3000], Loss: 0.2469, Accuracy: 0.05%\n",
      "Epoch [920/3000], Loss: 0.2485, Accuracy: 0.05%\n",
      "Epoch [930/3000], Loss: 0.2386, Accuracy: 0.06%\n",
      "Epoch [940/3000], Loss: 0.2401, Accuracy: 0.06%\n",
      "Epoch [950/3000], Loss: 0.2424, Accuracy: 0.05%\n",
      "Epoch [960/3000], Loss: 0.2311, Accuracy: 0.06%\n",
      "Epoch [970/3000], Loss: 0.2528, Accuracy: 0.04%\n",
      "Epoch [980/3000], Loss: 0.2268, Accuracy: 0.07%\n",
      "Epoch [990/3000], Loss: 0.2335, Accuracy: 0.06%\n",
      "Epoch [1000/3000], Loss: 0.2249, Accuracy: 0.07%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [1010/3000], Loss: 0.2351, Accuracy: 0.06%\n",
      "Epoch [1020/3000], Loss: 0.2248, Accuracy: 0.06%\n",
      "Epoch [1030/3000], Loss: 0.2243, Accuracy: 0.07%\n",
      "Epoch [1040/3000], Loss: 0.2214, Accuracy: 0.07%\n",
      "Epoch [1050/3000], Loss: 0.2307, Accuracy: 0.06%\n",
      "Epoch [1060/3000], Loss: 0.2136, Accuracy: 0.08%\n",
      "Epoch [1070/3000], Loss: 0.2302, Accuracy: 0.06%\n",
      "Epoch [1080/3000], Loss: 0.2073, Accuracy: 0.09%\n",
      "Epoch [1090/3000], Loss: 0.2078, Accuracy: 0.09%\n",
      "Epoch [1100/3000], Loss: 0.2217, Accuracy: 0.07%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [1110/3000], Loss: 0.2034, Accuracy: 0.10%\n",
      "Epoch [1120/3000], Loss: 0.2304, Accuracy: 0.05%\n",
      "Epoch [1130/3000], Loss: 0.1987, Accuracy: 0.11%\n",
      "Epoch [1140/3000], Loss: 0.2161, Accuracy: 0.07%\n",
      "Epoch [1150/3000], Loss: 0.2044, Accuracy: 0.09%\n",
      "Epoch [1160/3000], Loss: 0.1972, Accuracy: 0.11%\n",
      "Epoch [1170/3000], Loss: 0.2056, Accuracy: 0.08%\n",
      "Epoch [1180/3000], Loss: 0.1922, Accuracy: 0.11%\n",
      "Epoch [1190/3000], Loss: 0.2147, Accuracy: 0.07%\n",
      "Epoch [1200/3000], Loss: 0.1904, Accuracy: 0.11%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [1210/3000], Loss: 0.1922, Accuracy: 0.11%\n",
      "Epoch [1220/3000], Loss: 0.1976, Accuracy: 0.09%\n",
      "Epoch [1230/3000], Loss: 0.1858, Accuracy: 0.12%\n",
      "Epoch [1240/3000], Loss: 0.2337, Accuracy: 0.05%\n",
      "Epoch [1250/3000], Loss: 0.1818, Accuracy: 0.13%\n",
      "Epoch [1260/3000], Loss: 0.2114, Accuracy: 0.08%\n",
      "Epoch [1270/3000], Loss: 0.1812, Accuracy: 0.13%\n",
      "Epoch [1280/3000], Loss: 0.1896, Accuracy: 0.11%\n",
      "Epoch [1290/3000], Loss: 0.1955, Accuracy: 0.09%\n",
      "Epoch [1300/3000], Loss: 0.1758, Accuracy: 0.14%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [1310/3000], Loss: 0.2173, Accuracy: 0.07%\n",
      "Epoch [1320/3000], Loss: 0.1707, Accuracy: 0.15%\n",
      "Epoch [1330/3000], Loss: 0.1852, Accuracy: 0.12%\n",
      "Epoch [1340/3000], Loss: 0.1800, Accuracy: 0.12%\n",
      "Epoch [1350/3000], Loss: 0.1691, Accuracy: 0.16%\n",
      "Epoch [1360/3000], Loss: 0.2317, Accuracy: 0.05%\n",
      "Epoch [1370/3000], Loss: 0.1670, Accuracy: 0.15%\n",
      "Epoch [1380/3000], Loss: 0.1658, Accuracy: 0.16%\n",
      "Epoch [1390/3000], Loss: 0.2072, Accuracy: 0.07%\n",
      "Epoch [1400/3000], Loss: 0.1605, Accuracy: 0.17%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [1410/3000], Loss: 0.1900, Accuracy: 0.10%\n",
      "Epoch [1420/3000], Loss: 0.1676, Accuracy: 0.15%\n",
      "Epoch [1430/3000], Loss: 0.1635, Accuracy: 0.17%\n",
      "Epoch [1440/3000], Loss: 0.1767, Accuracy: 0.11%\n",
      "Epoch [1450/3000], Loss: 0.1561, Accuracy: 0.18%\n",
      "Epoch [1460/3000], Loss: 0.2157, Accuracy: 0.07%\n",
      "Epoch [1470/3000], Loss: 0.1557, Accuracy: 0.17%\n",
      "Epoch [1480/3000], Loss: 0.1558, Accuracy: 0.18%\n",
      "Epoch [1490/3000], Loss: 0.1863, Accuracy: 0.10%\n",
      "Epoch [1500/3000], Loss: 0.1509, Accuracy: 0.19%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [1510/3000], Loss: 0.1705, Accuracy: 0.13%\n",
      "Epoch [1520/3000], Loss: 0.1528, Accuracy: 0.18%\n",
      "Epoch [1530/3000], Loss: 0.1467, Accuracy: 0.20%\n",
      "Epoch [1540/3000], Loss: 0.2019, Accuracy: 0.08%\n",
      "Epoch [1550/3000], Loss: 0.1439, Accuracy: 0.20%\n",
      "Epoch [1560/3000], Loss: 0.2012, Accuracy: 0.08%\n",
      "Epoch [1570/3000], Loss: 0.1465, Accuracy: 0.19%\n",
      "Epoch [1580/3000], Loss: 0.1418, Accuracy: 0.22%\n",
      "Epoch [1590/3000], Loss: 0.1881, Accuracy: 0.09%\n",
      "Epoch [1600/3000], Loss: 0.1416, Accuracy: 0.21%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [1610/3000], Loss: 0.1468, Accuracy: 0.20%\n",
      "Epoch [1620/3000], Loss: 0.1698, Accuracy: 0.12%\n",
      "Epoch [1630/3000], Loss: 0.1354, Accuracy: 0.23%\n",
      "Epoch [1640/3000], Loss: 0.1580, Accuracy: 0.16%\n",
      "Epoch [1650/3000], Loss: 0.1503, Accuracy: 0.17%\n",
      "Epoch [1660/3000], Loss: 0.1324, Accuracy: 0.24%\n",
      "Epoch [1670/3000], Loss: 0.2128, Accuracy: 0.07%\n",
      "Epoch [1680/3000], Loss: 0.1323, Accuracy: 0.23%\n",
      "Epoch [1690/3000], Loss: 0.1313, Accuracy: 0.25%\n",
      "Epoch [1700/3000], Loss: 0.1647, Accuracy: 0.14%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [1710/3000], Loss: 0.1330, Accuracy: 0.23%\n",
      "Epoch [1720/3000], Loss: 0.1262, Accuracy: 0.26%\n",
      "Epoch [1730/3000], Loss: 0.1544, Accuracy: 0.17%\n",
      "Epoch [1740/3000], Loss: 0.1339, Accuracy: 0.22%\n",
      "Epoch [1750/3000], Loss: 0.1242, Accuracy: 0.27%\n",
      "Epoch [1760/3000], Loss: 0.1598, Accuracy: 0.15%\n",
      "Epoch [1770/3000], Loss: 0.1307, Accuracy: 0.23%\n",
      "Epoch [1780/3000], Loss: 0.1215, Accuracy: 0.28%\n",
      "Epoch [1790/3000], Loss: 0.1931, Accuracy: 0.08%\n",
      "Epoch [1800/3000], Loss: 0.1214, Accuracy: 0.27%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [1810/3000], Loss: 0.1220, Accuracy: 0.27%\n",
      "Epoch [1820/3000], Loss: 0.1698, Accuracy: 0.12%\n",
      "Epoch [1830/3000], Loss: 0.1177, Accuracy: 0.28%\n",
      "Epoch [1840/3000], Loss: 0.1200, Accuracy: 0.28%\n",
      "Epoch [1850/3000], Loss: 0.1681, Accuracy: 0.12%\n",
      "Epoch [1860/3000], Loss: 0.1150, Accuracy: 0.29%\n",
      "Epoch [1870/3000], Loss: 0.1192, Accuracy: 0.28%\n",
      "Epoch [1880/3000], Loss: 0.1521, Accuracy: 0.15%\n",
      "Epoch [1890/3000], Loss: 0.1133, Accuracy: 0.30%\n",
      "Epoch [1900/3000], Loss: 0.1330, Accuracy: 0.23%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [1910/3000], Loss: 0.1199, Accuracy: 0.26%\n",
      "Epoch [1920/3000], Loss: 0.1099, Accuracy: 0.31%\n",
      "Epoch [1930/3000], Loss: 0.1612, Accuracy: 0.14%\n",
      "Epoch [1940/3000], Loss: 0.1143, Accuracy: 0.29%\n",
      "Epoch [1950/3000], Loss: 0.1084, Accuracy: 0.32%\n",
      "Epoch [1960/3000], Loss: 0.1957, Accuracy: 0.09%\n",
      "Epoch [1970/3000], Loss: 0.1117, Accuracy: 0.29%\n",
      "Epoch [1980/3000], Loss: 0.1063, Accuracy: 0.33%\n",
      "Epoch [1990/3000], Loss: 0.1312, Accuracy: 0.22%\n",
      "Epoch [2000/3000], Loss: 0.1140, Accuracy: 0.28%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [2010/3000], Loss: 0.1041, Accuracy: 0.34%\n",
      "Epoch [2020/3000], Loss: 0.1148, Accuracy: 0.29%\n",
      "Epoch [2030/3000], Loss: 0.1217, Accuracy: 0.24%\n",
      "Epoch [2040/3000], Loss: 0.1008, Accuracy: 0.36%\n",
      "Epoch [2050/3000], Loss: 0.1077, Accuracy: 0.32%\n",
      "Epoch [2060/3000], Loss: 0.1296, Accuracy: 0.21%\n",
      "Epoch [2070/3000], Loss: 0.0996, Accuracy: 0.36%\n",
      "Epoch [2080/3000], Loss: 0.1088, Accuracy: 0.32%\n",
      "Epoch [2090/3000], Loss: 0.1177, Accuracy: 0.25%\n",
      "Epoch [2100/3000], Loss: 0.0969, Accuracy: 0.37%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [2110/3000], Loss: 0.1098, Accuracy: 0.31%\n",
      "Epoch [2120/3000], Loss: 0.1167, Accuracy: 0.25%\n",
      "Epoch [2130/3000], Loss: 0.0950, Accuracy: 0.38%\n",
      "Epoch [2140/3000], Loss: 0.1006, Accuracy: 0.36%\n",
      "Epoch [2150/3000], Loss: 0.1107, Accuracy: 0.28%\n",
      "Epoch [2160/3000], Loss: 0.0930, Accuracy: 0.39%\n",
      "Epoch [2170/3000], Loss: 0.0935, Accuracy: 0.39%\n",
      "Epoch [2180/3000], Loss: 0.1494, Accuracy: 0.15%\n",
      "Epoch [2190/3000], Loss: 0.0914, Accuracy: 0.39%\n",
      "Epoch [2200/3000], Loss: 0.0934, Accuracy: 0.40%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [2210/3000], Loss: 0.1547, Accuracy: 0.14%\n",
      "Epoch [2220/3000], Loss: 0.0894, Accuracy: 0.40%\n",
      "Epoch [2230/3000], Loss: 0.0889, Accuracy: 0.41%\n",
      "Epoch [2240/3000], Loss: 0.1917, Accuracy: 0.09%\n",
      "Epoch [2250/3000], Loss: 0.0884, Accuracy: 0.40%\n",
      "Epoch [2260/3000], Loss: 0.0859, Accuracy: 0.43%\n",
      "Epoch [2270/3000], Loss: 0.1590, Accuracy: 0.16%\n",
      "Epoch [2280/3000], Loss: 0.0908, Accuracy: 0.38%\n",
      "Epoch [2290/3000], Loss: 0.0843, Accuracy: 0.44%\n",
      "Epoch [2300/3000], Loss: 0.0937, Accuracy: 0.39%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [2310/3000], Loss: 0.1136, Accuracy: 0.25%\n",
      "Epoch [2320/3000], Loss: 0.0833, Accuracy: 0.43%\n",
      "Epoch [2330/3000], Loss: 0.0916, Accuracy: 0.39%\n",
      "Epoch [2340/3000], Loss: 0.1218, Accuracy: 0.23%\n",
      "Epoch [2350/3000], Loss: 0.0815, Accuracy: 0.45%\n",
      "Epoch [2360/3000], Loss: 0.0808, Accuracy: 0.46%\n",
      "Epoch [2370/3000], Loss: 0.2081, Accuracy: 0.09%\n",
      "Epoch [2380/3000], Loss: 0.0820, Accuracy: 0.44%\n",
      "Epoch [2390/3000], Loss: 0.0793, Accuracy: 0.47%\n",
      "Epoch [2400/3000], Loss: 0.0835, Accuracy: 0.44%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [2410/3000], Loss: 0.1021, Accuracy: 0.30%\n",
      "Epoch [2420/3000], Loss: 0.0771, Accuracy: 0.47%\n",
      "Epoch [2430/3000], Loss: 0.0766, Accuracy: 0.48%\n",
      "Epoch [2440/3000], Loss: 0.2132, Accuracy: 0.08%\n",
      "Epoch [2450/3000], Loss: 0.0774, Accuracy: 0.46%\n",
      "Epoch [2460/3000], Loss: 0.0748, Accuracy: 0.49%\n",
      "Epoch [2470/3000], Loss: 0.1824, Accuracy: 0.12%\n",
      "Epoch [2480/3000], Loss: 0.0789, Accuracy: 0.44%\n",
      "Epoch [2490/3000], Loss: 0.0731, Accuracy: 0.50%\n",
      "Epoch [2500/3000], Loss: 0.0978, Accuracy: 0.34%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [2510/3000], Loss: 0.0839, Accuracy: 0.40%\n",
      "Epoch [2520/3000], Loss: 0.0713, Accuracy: 0.51%\n",
      "Epoch [2530/3000], Loss: 0.0731, Accuracy: 0.50%\n",
      "Epoch [2540/3000], Loss: 0.1232, Accuracy: 0.22%\n",
      "Epoch [2550/3000], Loss: 0.0708, Accuracy: 0.50%\n",
      "Epoch [2560/3000], Loss: 0.0699, Accuracy: 0.53%\n",
      "Epoch [2570/3000], Loss: 0.2647, Accuracy: 0.06%\n",
      "Epoch [2580/3000], Loss: 0.0715, Accuracy: 0.49%\n",
      "Epoch [2590/3000], Loss: 0.0674, Accuracy: 0.54%\n",
      "Epoch [2600/3000], Loss: 0.0707, Accuracy: 0.52%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [2610/3000], Loss: 0.0964, Accuracy: 0.32%\n",
      "Epoch [2620/3000], Loss: 0.0662, Accuracy: 0.54%\n",
      "Epoch [2630/3000], Loss: 0.0658, Accuracy: 0.55%\n",
      "Epoch [2640/3000], Loss: 0.2048, Accuracy: 0.11%\n",
      "Epoch [2650/3000], Loss: 0.0699, Accuracy: 0.50%\n",
      "Epoch [2660/3000], Loss: 0.0635, Accuracy: 0.56%\n",
      "Epoch [2670/3000], Loss: 0.0648, Accuracy: 0.56%\n",
      "Epoch [2680/3000], Loss: 0.1583, Accuracy: 0.15%\n",
      "Epoch [2690/3000], Loss: 0.0635, Accuracy: 0.55%\n",
      "Epoch [2700/3000], Loss: 0.0607, Accuracy: 0.58%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [2710/3000], Loss: 0.0675, Accuracy: 0.53%\n",
      "Epoch [2720/3000], Loss: 0.0880, Accuracy: 0.36%\n",
      "Epoch [2730/3000], Loss: 0.0607, Accuracy: 0.58%\n",
      "Epoch [2740/3000], Loss: 0.0598, Accuracy: 0.59%\n",
      "Epoch [2750/3000], Loss: 0.2697, Accuracy: 0.07%\n",
      "Epoch [2760/3000], Loss: 0.0631, Accuracy: 0.54%\n",
      "Epoch [2770/3000], Loss: 0.0578, Accuracy: 0.60%\n",
      "Epoch [2780/3000], Loss: 0.0600, Accuracy: 0.59%\n",
      "Epoch [2790/3000], Loss: 0.1405, Accuracy: 0.18%\n",
      "Epoch [2800/3000], Loss: 0.0583, Accuracy: 0.59%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [2810/3000], Loss: 0.0553, Accuracy: 0.62%\n",
      "Epoch [2820/3000], Loss: 0.2240, Accuracy: 0.09%\n",
      "Epoch [2830/3000], Loss: 0.0583, Accuracy: 0.58%\n",
      "Epoch [2840/3000], Loss: 0.0543, Accuracy: 0.62%\n",
      "Epoch [2850/3000], Loss: 0.0559, Accuracy: 0.61%\n",
      "Epoch [2860/3000], Loss: 0.1050, Accuracy: 0.27%\n",
      "Epoch [2870/3000], Loss: 0.0539, Accuracy: 0.62%\n",
      "Epoch [2880/3000], Loss: 0.0520, Accuracy: 0.64%\n",
      "Epoch [2890/3000], Loss: 0.0567, Accuracy: 0.60%\n",
      "Epoch [2900/3000], Loss: 0.0773, Accuracy: 0.42%\n",
      "Saved model to: spectral_net_model.pth\n",
      "Epoch [2910/3000], Loss: 0.0512, Accuracy: 0.64%\n",
      "Epoch [2920/3000], Loss: 0.0509, Accuracy: 0.66%\n",
      "Epoch [2930/3000], Loss: 0.2161, Accuracy: 0.10%\n",
      "Epoch [2940/3000], Loss: 0.0541, Accuracy: 0.61%\n",
      "Epoch [2950/3000], Loss: 0.0490, Accuracy: 0.66%\n",
      "Epoch [2960/3000], Loss: 0.0487, Accuracy: 0.67%\n",
      "Epoch [2970/3000], Loss: 0.1983, Accuracy: 0.11%\n",
      "Epoch [2980/3000], Loss: 0.0503, Accuracy: 0.64%\n",
      "Epoch [2990/3000], Loss: 0.0468, Accuracy: 0.67%\n",
      "Epoch [3000/3000], Loss: 0.0486, Accuracy: 0.67%\n",
      "Saved model to: spectral_net_model.pth\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3000\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute accuracy\n",
    "        predictions = outputs.detach() >= 0.5\n",
    "        accuracy = torch.mean(torch.all(predictions == batch_y, dim=1).float())\n",
    "        epoch_accuracy += accuracy.item()\n",
    "\n",
    "    epoch_loss /= len(train_loader)\n",
    "    epoch_losses.append(epoch_loss)\n",
    "    epoch_accuracy /= len(train_loader)\n",
    "    epoch_accuracies.append(epoch_accuracy)\n",
    "\n",
    "\n",
    "    # Print the loss and accuracy every 100 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "     \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        torch.save(model.state_dict(), \"spectral_net_model.pth\") ## save the model every 100 epochs\n",
    "        print(\"Saved model to:\", \"spectral_net_model.pth\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow it to train and then check the outputs of the model \n",
    "# increase the complexity of the model with 2 layers and do not change hyperparameters and then run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0000\n",
      "Precision for each class: [0.         0.50243902 0.5        0.45673077 0.56521739 0.52840909\n",
      " 0.45283019 0.49537037 0.49769585 0.52763819 0.51219512 0.51851852\n",
      " 0.48858447 0.5212766  0.44239631 0.50925926 0.51295337 0.5255102\n",
      " 0.48958333 0.44230769 0.47715736 0.53809524 0.49468085 0.54589372\n",
      " 0.52791878 0.48058252 0.53333333 0.43718593 0.48039216 0.50273224\n",
      " 0.47058824 0.5        0.52197802 0.49509804 0.46268657 0.50485437]\n",
      "Recall for each class: [0.         0.5255102  0.44607843 0.4973822  0.52702703 0.45812808\n",
      " 0.5106383  0.53768844 0.5625     0.49065421 0.5        0.49246231\n",
      " 0.54871795 0.49246231 0.47761194 0.56122449 0.48529412 0.5255102\n",
      " 0.47715736 0.54761905 0.47474747 0.53554502 0.5        0.56218905\n",
      " 0.51485149 0.52659574 0.46846847 0.47540984 0.49       0.43809524\n",
      " 0.47761194 0.50505051 0.47979798 0.52061856 0.48691099 0.51231527]\n",
      "F1-score for each class: [0.         0.51371571 0.47150259 0.47619048 0.54545455 0.49076517\n",
      " 0.48       0.51566265 0.52811736 0.50847458 0.5060241  0.50515464\n",
      " 0.51690821 0.50645995 0.45933014 0.53398058 0.49874055 0.5255102\n",
      " 0.48329049 0.4893617  0.47594937 0.5368171  0.4973262  0.55392157\n",
      " 0.52130326 0.50253807 0.49880096 0.45549738 0.48514851 0.46819338\n",
      " 0.47407407 0.50251256 0.5        0.50753769 0.4744898  0.50855746]\n",
      "Micro-averaged Precision: 0.4984\n",
      "Micro-averaged Recall: 0.5033\n",
      "Micro-averaged F1-score: 0.5009\n",
      "Macro-averaged Precision: 0.4851\n",
      "Macro-averaged Recall: 0.4898\n",
      "Macro-averaged F1-score: 0.4866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanazkazeminia/anaconda3/envs/Mass_Spec/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sanazkazeminia/anaconda3/envs/Mass_Spec/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sanazkazeminia/anaconda3/envs/Mass_Spec/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/Users/sanazkazeminia/anaconda3/envs/Mass_Spec/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sanazkazeminia/anaconda3/envs/Mass_Spec/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sanazkazeminia/anaconda3/envs/Mass_Spec/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming you have the following variables:\n",
    "# - model: Your trained PyTorch model\n",
    "# - X_val: Validation or test input data\n",
    "# - y_test: True labels for the validation or test set\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_val)\n",
    "    predictions = outputs.cpu().numpy() >= 0.5\n",
    "    y_true = y_val.cpu().numpy()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, predictions)\n",
    "print(f\"Accuracy: {accuracy:.4f}\") ## cant be used for multi label classification \n",
    "\n",
    "# Calculate precision for each class\n",
    "precision = precision_score(y_true, predictions, average=None)\n",
    "print(f\"Precision for each class: {precision}\")\n",
    "\n",
    "# Calculate recall for each class\n",
    "recall = recall_score(y_true, predictions, average=None)\n",
    "print(f\"Recall for each class: {recall}\")\n",
    "\n",
    "# Calculate F1-score for each class\n",
    "f1 = f1_score(y_true, predictions, average=None)\n",
    "print(f\"F1-score for each class: {f1}\")\n",
    "\n",
    "# Calculate micro-averaged precision, recall, and F1-score\n",
    "micro_precision = precision_score(y_true, predictions, average='micro')\n",
    "micro_recall = recall_score(y_true, predictions, average='micro')\n",
    "micro_f1 = f1_score(y_true, predictions, average='micro')\n",
    "print(f\"Micro-averaged Precision: {micro_precision:.4f}\")\n",
    "print(f\"Micro-averaged Recall: {micro_recall:.4f}\")\n",
    "print(f\"Micro-averaged F1-score: {micro_f1:.4f}\")\n",
    "\n",
    "# Calculate macro-averaged precision, recall, and F1-score\n",
    "macro_precision = precision_score(y_true, predictions, average='macro')\n",
    "macro_recall = recall_score(y_true, predictions, average='macro')\n",
    "macro_f1 = f1_score(y_true, predictions, average='macro')\n",
    "print(f\"Macro-averaged Precision: {macro_precision:.4f}\")\n",
    "print(f\"Macro-averaged Recall: {macro_recall:.4f}\")\n",
    "print(f\"Macro-averaged F1-score: {macro_f1:.4f}\")\n",
    "\n",
    "\n",
    "## for each specta make f1 score then vary the threshold and see how it changes then average.\n",
    "## miro aupr and macro aupr trapezoidal rule for each column (class) precision recall curve from all the data\n",
    "## average and then plot the aupr curve for each class.\n",
    "## find the blogs \n",
    "## kflod cross validation has to be done for each model and then the average of the results has to be taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mass_Spec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
