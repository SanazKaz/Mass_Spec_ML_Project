{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft\n",
    "import torch \n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "with open ('interaction_matrices.pkl', 'rb') as int_matrices:\n",
    "    interaction_matrices = pickle.load(int_matrices)\n",
    "\n",
    "with open ('spectra_dataset.pkl', 'rb') as spec_dataset:\n",
    "    spec_dataset = pickle.load(spec_dataset)\n",
    "\n",
    "\n",
    "# converting the dataset to numpy arrays\n",
    "\n",
    "interaction_matrices = interaction_matrices.numpy()\n",
    "spec_dataset = spec_dataset.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 20000)\n",
      "(10000, 6, 6)\n"
     ]
    }
   ],
   "source": [
    "print(spec_dataset.shape)\n",
    "print(interaction_matrices.shape)\n",
    "\n",
    "# data is in good shape \n",
    "# NMF Y ~ WH\n",
    "# Y is the dataset\n",
    "# W IS THE BASIS MATRIX AND H IS THE COEFFICIENT MATRIX\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 20000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanazkazeminia/anaconda3/envs/Mass_Spec/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py:1710: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forbenius norm error: 0.0010816733\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "selected_spec = spec_dataset[:10000,:]\n",
    "print(selected_spec.shape)\n",
    "\n",
    "# W becomes the basis matrix holding the features i will use for the CNN\n",
    "model = NMF(n_components=75, init='nndsvd', random_state=40, max_iter=200, beta_loss='frobenius')\n",
    "W = model.fit_transform(selected_spec)\n",
    "H = model.components_\n",
    "\n",
    "approximation = np.dot(W,H)\n",
    "\n",
    "reconstruction_error = np.linalg.norm(selected_spec - approximation, 'fro')\n",
    "print(\"Forbenius norm error:\", reconstruction_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(75, 20000)\n"
     ]
    }
   ],
   "source": [
    "print(H[2])\n",
    "print(H.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 6, 6])\n",
      "torch.int64\n",
      "torch.int64\n",
      "torch.Size([10000, 6, 6])\n",
      "torch.Size([10000, 6, 6, 7])\n",
      "torch.int64\n",
      "torch.Size([10000, 75])\n",
      "torch.float32\n",
      "the binary matrices dtype is torch.float32\n",
      "Binary Targets Shape: torch.Size([10000, 6, 6])\n",
      "Sample Binary Target: tensor([[0., 0., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 0., 1.],\n",
      "        [0., 0., 1., 1., 1., 0.],\n",
      "        [0., 1., 0., 0., 1., 0.]])\n",
      "tensor([[0, 0, 0, 5, 0, 0],\n",
      "        [2, 0, 0, 0, 5, 0],\n",
      "        [1, 0, 3, 2, 5, 5],\n",
      "        [2, 2, 1, 3, 0, 6],\n",
      "        [0, 0, 3, 3, 1, 0],\n",
      "        [0, 2, 0, 0, 5, 0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/02/fvfmdq_j709g1tthj47t5fcm0000gn/T/ipykernel_10776/739251209.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  interaction_matrices = torch.tensor(interaction_matrices)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn.functional as Fun \n",
    "import numpy as np\n",
    "\n",
    "# need to convert back to tensors then convert from float to int for one hot encoding\n",
    "\n",
    "interaction_matrices = torch.tensor(interaction_matrices)\n",
    "print(interaction_matrices.shape)\n",
    "print(interaction_matrices.dtype)\n",
    "\n",
    "interaction_matrices = interaction_matrices.to(torch.long)\n",
    "print(interaction_matrices.dtype)\n",
    "print(interaction_matrices.shape)\n",
    "\n",
    "one_hot_encoding = Fun.one_hot(interaction_matrices, num_classes=7)\n",
    "print(one_hot_encoding.shape)\n",
    "print(one_hot_encoding.dtype)\n",
    "\n",
    "spectra_data = torch.tensor(W)\n",
    "print(spectra_data.shape)\n",
    "print(spectra_data.dtype)\n",
    "\n",
    "\n",
    "# attempting to split problem into 2 - first 0 or not then abundance.\n",
    "\n",
    "# Convert to binary format where any presence of stoichiometry (non-zero class index) is marked as 1\n",
    "\n",
    "# Step 1: Determine if the class index is greater than 0 (absence is class 0)\n",
    "binary_matrices = torch.argmax(one_hot_encoding, dim=-1)  # Convert one-hot to indices [N, 6, 6]\n",
    "binary_matrices = (binary_matrices > 0).float()  # Convert indices to binary (1 if presence, 0 if absence)\n",
    "print(f\"the binary matrices dtype is {binary_matrices.dtype}\")\n",
    "\n",
    "print(\"Binary Targets Shape:\", binary_matrices.shape)  # Should be [N, 6, 6]\n",
    "print(\"Sample Binary Target:\", binary_matrices[0])  # Display the first converted binary target matrix\n",
    "print(interaction_matrices[0])  # Display the original interaction matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "spectra_data = spectra_data.float()\n",
    "print(spectra_data.dtype)\n",
    "#binary is the matrices one hot encoded and the spec_train and test is W.\n",
    "# to return to V we can multiply W by H to get the approximation of the original dataset\n",
    "spec_train, spec_test, binary_train, binary_test = train_test_split(spectra_data, binary_matrices, test_size=0.2, random_state=42)\n",
    "spec_test, spec_val, binary_test, binary_val = train_test_split(spec_test, binary_test, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(spec_train.dtype)\n",
    "print(binary_train.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpectraCNN(\n",
      "  (conv1): Conv1d(1, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc1): Linear(in_features=576, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=36, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class SpectraCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpectraCNN, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        # Calculate the size after convolutions and pooling\n",
    "        self.fc1 = nn.Linear(32 * 18, 128)  # Adjust the size according to your exact dimensions\n",
    "        self.fc2 = nn.Linear(128, 36)  # Output 36 units, one for each position in the 6x6 matrix\n",
    "\n",
    "        # Activation function\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # Flatten the convolutions\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)  # Sigmoid activation to output probabilities between 0 and 1\n",
    "        return x.view(-1, 6, 6)  # Reshape to 6x6 matrix for each sample in the batch\n",
    "\n",
    "# Instantiate the model\n",
    "model = SpectraCNN()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8000, 75])\n",
      "torch.Size([8000, 1, 75])\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/02/fvfmdq_j709g1tthj47t5fcm0000gn/T/ipykernel_10776/2217302572.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spec_train = torch.tensor(spec_train, dtype=torch.float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "spec_train = spec_train.squeeze()  # This will remove all singleton dimensions\n",
    "print(spec_train.shape)\n",
    "\n",
    "spec_train = spec_train.unsqueeze(1)  # This will add a singleton dimension at the second position\n",
    "print(spec_train.shape)\n",
    "spec_train = torch.tensor(spec_train, dtype=torch.float32)\n",
    "print(spec_train.dtype)\n",
    "\n",
    "train_dataset = TensorDataset(spec_train, binary_train)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "spec_train.dtype\n",
    "binary_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.6932\n",
      "Epoch [2/50], Loss: 0.6931\n",
      "Epoch [3/50], Loss: 0.6932\n",
      "Epoch [4/50], Loss: 0.6932\n",
      "Epoch [5/50], Loss: 0.6931\n",
      "Epoch [6/50], Loss: 0.6932\n",
      "Epoch [7/50], Loss: 0.6931\n",
      "Epoch [8/50], Loss: 0.6931\n",
      "Epoch [9/50], Loss: 0.6931\n",
      "Epoch [10/50], Loss: 0.6931\n",
      "Epoch [11/50], Loss: 0.6931\n",
      "Epoch [12/50], Loss: 0.6931\n",
      "Epoch [13/50], Loss: 0.6932\n",
      "Epoch [14/50], Loss: 0.6931\n",
      "Epoch [15/50], Loss: 0.6931\n",
      "Epoch [16/50], Loss: 0.6931\n",
      "Epoch [17/50], Loss: 0.6931\n",
      "Epoch [18/50], Loss: 0.6930\n",
      "Epoch [19/50], Loss: 0.6932\n",
      "Epoch [20/50], Loss: 0.6932\n",
      "Epoch [21/50], Loss: 0.6931\n",
      "Epoch [22/50], Loss: 0.6930\n",
      "Epoch [23/50], Loss: 0.6931\n",
      "Epoch [24/50], Loss: 0.6931\n",
      "Epoch [25/50], Loss: 0.6931\n",
      "Epoch [26/50], Loss: 0.6931\n",
      "Epoch [27/50], Loss: 0.6932\n",
      "Epoch [28/50], Loss: 0.6930\n",
      "Epoch [29/50], Loss: 0.6931\n",
      "Epoch [30/50], Loss: 0.6930\n",
      "Epoch [31/50], Loss: 0.6928\n",
      "Epoch [32/50], Loss: 0.6930\n",
      "Epoch [33/50], Loss: 0.6930\n",
      "Epoch [34/50], Loss: 0.6929\n",
      "Epoch [35/50], Loss: 0.6931\n",
      "Epoch [36/50], Loss: 0.6931\n",
      "Epoch [37/50], Loss: 0.6931\n",
      "Epoch [38/50], Loss: 0.6931\n",
      "Epoch [39/50], Loss: 0.6930\n",
      "Epoch [40/50], Loss: 0.6931\n",
      "Epoch [41/50], Loss: 0.6931\n",
      "Epoch [42/50], Loss: 0.6930\n",
      "Epoch [43/50], Loss: 0.6929\n",
      "Epoch [44/50], Loss: 0.6930\n",
      "Epoch [45/50], Loss: 0.6931\n",
      "Epoch [46/50], Loss: 0.6930\n",
      "Epoch [47/50], Loss: 0.6930\n",
      "Epoch [48/50], Loss: 0.6931\n",
      "Epoch [49/50], Loss: 0.6931\n",
      "Epoch [50/50], Loss: 0.6929\n"
     ]
    }
   ],
   "source": [
    "# Initialize model, optimizer, and loss function\n",
    "model = SpectraCNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Assuming your DataLoader setup is correct\n",
    "# Train model\n",
    "num_epochs = 50\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for spectra, matrices in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(spectra)\n",
    "        #print(outputs[0:4])\n",
    "        # Ensure target is of the correct shape, with no channel dimension and type long\n",
    "        matrices = matrices.long()\n",
    "        loss = criterion(outputs, matrices.float())  # outputs should be [N, C, d1, d2], matrices should be [N, d1, d2]\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0.],\n",
      "         [1., 0., 0., 1., 1., 1.],\n",
      "         [0., 1., 1., 1., 1., 1.],\n",
      "         [0., 1., 0., 1., 0., 1.],\n",
      "         [1., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 1., 1., 0.],\n",
      "         [0., 0., 0., 1., 1., 0.],\n",
      "         [1., 1., 1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0.],\n",
      "         [1., 1., 1., 0., 1., 1.],\n",
      "         [0., 1., 1., 0., 0., 1.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0., 0.],\n",
      "         [1., 0., 1., 1., 1., 0.],\n",
      "         [0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 1., 1., 0., 1.],\n",
      "         [0., 0., 1., 1., 0., 0.],\n",
      "         [0., 0., 0., 1., 1., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 1., 1., 0., 1.],\n",
      "         [1., 0., 1., 0., 1., 0.],\n",
      "         [1., 1., 1., 0., 0., 0.],\n",
      "         [1., 0., 1., 0., 1., 1.],\n",
      "         [1., 1., 0., 1., 0., 1.],\n",
      "         [0., 0., 0., 1., 0., 1.]],\n",
      "\n",
      "        [[0., 1., 1., 1., 1., 0.],\n",
      "         [0., 0., 0., 0., 1., 0.],\n",
      "         [1., 0., 1., 0., 1., 1.],\n",
      "         [0., 0., 1., 0., 1., 0.],\n",
      "         [1., 1., 0., 1., 1., 0.],\n",
      "         [0., 0., 1., 1., 0., 1.]],\n",
      "\n",
      "        [[0., 0., 1., 1., 0., 1.],\n",
      "         [0., 1., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0., 1.],\n",
      "         [1., 1., 0., 0., 0., 0.],\n",
      "         [0., 1., 1., 0., 0., 0.]]])\n",
      "torch.Size([64, 6, 6])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Target Indices Shape: torch.Size([10000, 6, 6])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mass_Spec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
